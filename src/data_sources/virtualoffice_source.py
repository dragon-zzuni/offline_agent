# -*- coding: utf-8 -*-
"""
VirtualOffice Data Source
VirtualOffice API ê¸°ë°˜ ë°ì´í„° ì†ŒìŠ¤
"""
import asyncio
import logging
import os
import time
import sqlite3
from bisect import bisect_right
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any, Optional, Tuple

from data_sources.manager import DataSource
from integrations.virtualoffice_client import VirtualOfficeClient
from integrations.converters import (
    convert_email_to_internal_format,
    convert_message_to_internal_format,
    build_persona_maps
)
from utils.vdos_connector import VDOSConnector

logger = logging.getLogger(__name__)


class VirtualOfficeDataSource(DataSource):
    """VirtualOffice API ê¸°ë°˜ ë°ì´í„° ì†ŒìŠ¤"""
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •
    MAX_MESSAGES = 10000  # ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜
    CLEANUP_THRESHOLD = 11000  # ì •ë¦¬ ì‹œì‘ ì„ê³„ê°’
    
    def __init__(self, client: VirtualOfficeClient, selected_persona: Dict[str, Any]):
        """
        Args:
            client: VirtualOfficeClient ì¸ìŠ¤í„´ìŠ¤
            selected_persona: ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ì •ë³´
        """
        self.client = client
        self.selected_persona = selected_persona
        self.last_email_id = 0
        self.last_message_id = 0
        
        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ìºì‹±
        self.personas: List[Dict[str, Any]] = []
        self.persona_by_email: Dict[str, Dict[str, Any]] = {}
        self.persona_by_handle: Dict[str, Dict[str, Any]] = {}
        
        # ë©”ì‹œì§€ ìºì‹œ (ë©”ëª¨ë¦¬ ê´€ë¦¬ìš©)
        self.cached_messages: List[Dict[str, Any]] = []

        # ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ë§¤í•‘
        self._tick_datetimes: List[datetime] = []
        self._tick_values: List[int] = []
        self._sim_base_dt: Optional[datetime] = None
        try:
            self._sim_hours_per_day = max(1, int(os.getenv("VDOS_HOURS_PER_DAY", "8")))
        except ValueError:
            self._sim_hours_per_day = 8
        self._vdos_connector: Optional[VDOSConnector] = None
        
        # ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ìºì‹œ
        self._cached_sim_status: Optional[Dict[str, Any]] = None
        self._sim_status_cache_time: float = 0
        self._sim_status_cache_ttl: float = 2.0  # 2ì´ˆ TTL
        
        # ì´ˆê¸°í™” ì‹œ í˜ë¥´ì†Œë‚˜ ë¡œë“œ
        self._load_personas()
        self._initialize_simulation_clock()
        
        logger.info(
            f"VirtualOfficeDataSource ì´ˆê¸°í™”: "
            f"í˜ë¥´ì†Œë‚˜={selected_persona.get('name', 'Unknown')}"
        )
    
    def _load_personas(self) -> None:
        """í˜ë¥´ì†Œë‚˜ ì •ë³´ ë¡œë“œ ë° ìºì‹±"""
        try:
            self.personas = self.client.get_personas()
            self.persona_by_email, self.persona_by_handle = build_persona_maps(self.personas)
            logger.info(f"í˜ë¥´ì†Œë‚˜ ë¡œë“œ ì™„ë£Œ: {len(self.personas)}ëª…")
        except Exception as e:
            logger.error(f"í˜ë¥´ì†Œë‚˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.personas = []
            self.persona_by_email = {}
            self.persona_by_handle = {}

    def _initialize_simulation_clock(self) -> None:
        """ì‹œë®¬ë ˆì´ì…˜ tick â†’ datetime ë§¤í•‘ ì´ˆê¸°í™”"""
        try:
            if not self._vdos_connector:
                self._vdos_connector = VDOSConnector()
            if not self._vdos_connector or not self._vdos_connector.is_available:
                logger.warning("VDOS DBë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ë§¤í•‘ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return

            db_path = self._vdos_connector.vdos_db_path
            with sqlite3.connect(f"file:{db_path}?immutable=1", uri=True) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT tick, created_at FROM tick_log ORDER BY tick ASC")
                rows = cursor.fetchall()

            if not rows:
                logger.warning("tick_log ë°ì´í„°ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ë§¤í•‘ì„ êµ¬ì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            tick_datetimes: List[datetime] = []
            tick_values: List[int] = []
            for row in rows:
                created_at = row["created_at"]
                tick = int(row["tick"])
                try:
                    dt = self._parse_db_datetime(created_at)
                except Exception:
                    continue
                tick_datetimes.append(dt)
                tick_values.append(tick)

            if not tick_datetimes:
                logger.warning("tick_logì˜ datetime íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return

            self._tick_datetimes = tick_datetimes
            self._tick_values = tick_values
            self._sim_base_dt = tick_datetimes[0]
            logger.info(
                "ì‹œë®¬ë ˆì´ì…˜ ì‹œê³„ ì´ˆê¸°í™” ì™„ë£Œ: base=%s, ticks=%d",
                self._sim_base_dt.isoformat(),
                tick_values[-1],
            )
        except Exception as e:
            logger.warning(f"ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ë§¤í•‘ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)

    @staticmethod
    def _parse_db_datetime(value: str) -> datetime:
        """SQLite timestampë¥¼ UTC aware datetimeìœ¼ë¡œ ë³€í™˜"""
        if not value:
            raise ValueError("ë¹ˆ datetime ë¬¸ìì—´ì…ë‹ˆë‹¤.")
        normalized = value.replace("Z", "+00:00")
        if "T" not in normalized and "+" not in normalized[10:]:
            return datetime.fromisoformat(normalized).replace(tzinfo=timezone.utc)
        return datetime.fromisoformat(normalized).astimezone(timezone.utc)

    def _safe_parse_iso_datetime(self, value: Optional[str]) -> Optional[datetime]:
        """ë©”ì‹œì§€ ë‚ ì§œ ë¬¸ìì—´ì„ UTC aware datetimeìœ¼ë¡œ ë³€í™˜"""
        if not value:
            return None
        try:
            normalized = value.replace("Z", "+00:00")
            if "T" not in normalized and "+" not in normalized[10:]:
                return datetime.fromisoformat(normalized).replace(tzinfo=timezone.utc)
            return datetime.fromisoformat(normalized).astimezone(timezone.utc)
        except Exception:
            return None

    def _infer_tick_for_datetime(self, dt: datetime) -> Optional[int]:
        """ì‹¤ì œ ë°œìƒ ì‹œê°ìœ¼ë¡œë¶€í„° ì‹œë®¬ë ˆì´ì…˜ tick ì¶”ì •"""
        if not self._tick_datetimes or not self._tick_values:
            return None
        idx = bisect_right(self._tick_datetimes, dt)
        if idx <= 0:
            return self._tick_values[0]
        if idx >= len(self._tick_values):
            return self._tick_values[-1]
        return self._tick_values[idx - 1]

    def _compute_sim_datetime_from_tick(self, tick: int) -> Optional[Tuple[datetime, int, int]]:
        """tickì„ ì‹œë®¬ë ˆì´ì…˜ datetimeìœ¼ë¡œ ë³€í™˜"""
        if not self._sim_base_dt:
            return None
        tick = max(1, tick)
        day_ticks = max(1, self._sim_hours_per_day * 60)
        tick_index = tick - 1
        day_index = tick_index // day_ticks
        tick_of_day = tick_index % day_ticks
        minutes_24h = int((tick_of_day / day_ticks) * 1440)
        sim_dt = self._sim_base_dt + timedelta(days=day_index, minutes=minutes_24h)
        return sim_dt, day_index, minutes_24h

    def _annotate_simulation_timestamps(self, messages: List[Dict[str, Any]]) -> None:
        """ë©”ì‹œì§€ì— ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ ì£¼ì…"""
        if not messages or not self._sim_base_dt or not self._tick_datetimes:
            return

        for msg in messages:
            metadata = msg.get("metadata") or {}
            source_date = (
                metadata.get("original_date")
                or msg.get("date")
                or msg.get("timestamp")
                or msg.get("datetime")
            )
            msg_dt = self._safe_parse_iso_datetime(source_date)
            if not msg_dt:
                continue

            if msg_dt <= self._tick_datetimes[0]:
                tick = self._tick_values[0]
            elif msg_dt >= self._tick_datetimes[-1]:
                tick = self._tick_values[-1]
            else:
                tick = self._infer_tick_for_datetime(msg_dt)
            if not tick:
                continue

            result = self._compute_sim_datetime_from_tick(tick)
            if not result:
                continue

            sim_dt, day_index, minutes_24h = result
            hours = minutes_24h // 60
            minutes = minutes_24h % 60

            if source_date and "original_date" not in metadata:
                metadata["original_date"] = source_date

            metadata["sim_tick"] = tick
            metadata["sim_day_index"] = day_index + 1
            metadata["sim_time"] = f"Day {day_index + 1} {hours:02d}:{minutes:02d}"
            msg["metadata"] = metadata

            msg["simulated_datetime"] = sim_dt.isoformat()
            msg["sim_day_index"] = day_index + 1
            msg["sim_week_index"] = day_index // 7 + 1
            msg["sim_month_index"] = day_index // 30 + 1
            msg["date"] = sim_dt.isoformat()
    
    async def collect_messages(self, options: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        VirtualOffice APIì—ì„œ ë©”ì‹œì§€ ìˆ˜ì§‘
        
        Args:
            options: ìˆ˜ì§‘ ì˜µì…˜
                - incremental: Trueë©´ ì¦ë¶„ ìˆ˜ì§‘, Falseë©´ ì „ì²´ ìˆ˜ì§‘ (ê¸°ë³¸ê°’: False)
                - parallel: Trueë©´ ë³‘ë ¬ ìˆ˜ì§‘, Falseë©´ ìˆœì°¨ ìˆ˜ì§‘ (ê¸°ë³¸ê°’: True)
                - time_range: ì‹œê°„ ë²”ìœ„ í•„í„°ë§ {"start": datetime, "end": datetime}
            
        Returns:
            ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        options = options or {}
        incremental = options.get("incremental", False)
        parallel = options.get("parallel", True)
        time_range = options.get("time_range")
        
        # ì„ íƒëœ í˜ë¥´ì†Œë‚˜ì˜ ë©”ì¼ë°•ìŠ¤ì™€ í•¸ë“¤
        mailbox = self.selected_persona.get("email_address")
        handle = (self.selected_persona.get("chat_handle") or "").strip()
        
        if not mailbox or not handle:
            logger.error("ì„ íƒëœ í˜ë¥´ì†Œë‚˜ì— email_address ë˜ëŠ” chat_handleì´ ì—†ìŠµë‹ˆë‹¤")
            return []
        
        # í•¸ë“¤ì„ ì†Œë¬¸ìë¡œ ë³€í™˜ (VDOS ë°ì´í„°ë² ì´ìŠ¤ ëŒ€ì†Œë¬¸ì ë¶ˆì¼ì¹˜ í•´ê²°)
        normalized_handle = handle.lower()
        
        logger.info(
            f"ë©”ì‹œì§€ ìˆ˜ì§‘ ì‹œì‘ (ì¦ë¶„={incremental}, ë³‘ë ¬={parallel}): "
            f"mailbox={mailbox}, handle={normalized_handle}"
        )
        
        # ì¦ë¶„ ìˆ˜ì§‘ ì‹œ since_id ì‚¬ìš©
        since_email_id = self.last_email_id if incremental else None
        since_message_id = self.last_message_id if incremental else None
        
        # API í˜¸ì¶œ (ë³‘ë ¬ ë˜ëŠ” ìˆœì°¨)
        try:
            if parallel:
                raw_emails, raw_messages = await self._collect_parallel(
                    mailbox, normalized_handle, since_email_id, since_message_id
                )
            else:
                raw_emails = self.client.get_emails(mailbox, since_id=since_email_id)
                raw_messages = self.client.get_messages(
                    normalized_handle, since_id=since_message_id
                )
        except Exception as e:
            logger.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return []
        
        # ë°ì´í„° ë³€í™˜ (ì„±ëŠ¥ ì¸¡ì •)
        start_time = time.time()
        emails = [
            convert_email_to_internal_format(e, self.persona_by_email, mailbox)
            for e in raw_emails
        ]
        email_time = time.time() - start_time
        
        start_time = time.time()
        messages = [
            convert_message_to_internal_format(
                m,
                self.persona_by_handle,
                selected_persona_handle=handle
            )
            for m in raw_messages
        ]
        message_time = time.time() - start_time
        
        logger.info(
            f"â±ï¸ ë³€í™˜ ì‹œê°„: ì´ë©”ì¼ {email_time:.2f}ì´ˆ ({len(raw_emails)}ê°œ), "
            f"ë©”ì‹œì§€ {message_time:.2f}ì´ˆ ({len(raw_messages)}ê°œ)"
        )
        
        # last_id ì—…ë°ì´íŠ¸
        if raw_emails:
            self.last_email_id = max(e["id"] for e in raw_emails)
        if raw_messages:
            self.last_message_id = max(m["id"] for m in raw_messages)
        
        # í†µí•© ë° ì •ë ¬
        all_messages = emails + messages
        
        # msg_id ê¸°ì¤€ ì¤‘ë³µ ì œê±° (TO/CC ì¤‘ë³µ ìˆ˜ì‹  ì²˜ë¦¬) - ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        seen_msg_ids = set()
        unique_messages = []
        for msg in all_messages:
            msg_id = msg.get("msg_id")
            if msg_id and msg_id not in seen_msg_ids:
                seen_msg_ids.add(msg_id)
                unique_messages.append(msg)
            elif not msg_id:
                # msg_idê°€ ì—†ëŠ” ê²½ìš°ëŠ” ê·¸ëŒ€ë¡œ ì¶”ê°€
                unique_messages.append(msg)
        
        dedup_time = time.time() - start_time
        
        if len(all_messages) != len(unique_messages):
            logger.info(
                f"ğŸ” ì¤‘ë³µ ë©”ì‹œì§€ ì œê±°: {len(all_messages)}ê°œ â†’ {len(unique_messages)}ê°œ "
                f"({len(all_messages) - len(unique_messages)}ê°œ ì¤‘ë³µ) - {dedup_time:.2f}ì´ˆ"
            )
        
        all_messages = unique_messages

        # ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ë©”íƒ€ë°ì´í„° ì£¼ì…
        self._annotate_simulation_timestamps(all_messages)
        
        # ì •ë ¬ - ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        all_messages.sort(key=lambda m: m["date"])
        sort_time = time.time() - start_time
        logger.info(f"â±ï¸ ì •ë ¬ ì‹œê°„: {sort_time:.2f}ì´ˆ ({len(all_messages)}ê°œ)")
        
        # ì‹œê°„ ë²”ìœ„ í•„í„°ë§ ì ìš© (ì˜µì…˜)
        if time_range:
            all_messages = self._apply_time_filter(all_messages, time_range)
            logger.info(f"â° ì‹œê°„ í•„í„°ë§ ì ìš©: {time_range['start']} ~ {time_range['end']}")
        
        logger.info(
            f"ë©”ì‹œì§€ ìˆ˜ì§‘ ì™„ë£Œ: ì´ë©”ì¼ {len(emails)}ê°œ, ì±„íŒ… {len(messages)}ê°œ "
            f"(last_email_id={self.last_email_id}, last_message_id={self.last_message_id})"
        )
        
        return all_messages
    
    async def _collect_parallel(
        self, 
        mailbox: str, 
        handle: str, 
        since_email_id: Optional[int], 
        since_message_id: Optional[int]
    ) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """
        ë³‘ë ¬ë¡œ ì´ë©”ì¼ê³¼ ë©”ì‹œì§€ ìˆ˜ì§‘
        
        Args:
            mailbox: ë©”ì¼ë°•ìŠ¤ ì£¼ì†Œ
            handle: ì±„íŒ… í•¸ë“¤
            since_email_id: ë§ˆì§€ë§‰ ì´ë©”ì¼ ID
            since_message_id: ë§ˆì§€ë§‰ ë©”ì‹œì§€ ID
        
        Returns:
            (ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸, ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
        """
        # ë¹„ë™ê¸° íƒœìŠ¤í¬ ìƒì„±
        email_task = asyncio.to_thread(
            self.client.get_emails, mailbox, since_id=since_email_id
        )
        message_task = asyncio.to_thread(
            self.client.get_messages, handle, since_id=since_message_id
        )
        
        # ë³‘ë ¬ ì‹¤í–‰
        raw_emails, raw_messages = await asyncio.gather(
            email_task, message_task, return_exceptions=False
        )
        
        return raw_emails, raw_messages
    
    async def collect_new_data_batch(self) -> Dict[str, Any]:
        """
        ë³‘ë ¬ë¡œ ìƒˆ ë°ì´í„° ìˆ˜ì§‘ (ì¦ë¶„ ìˆ˜ì§‘ ì „ìš©)
        
        ì´ ë©”ì„œë“œëŠ” PollingWorkerì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ìµœì í™”ëœ ë°°ì¹˜ ìˆ˜ì§‘ ë©”ì„œë“œì…ë‹ˆë‹¤.
        ì´ë©”ì¼ê³¼ ë©”ì‹œì§€ë¥¼ ë³‘ë ¬ë¡œ ì¡°íšŒí•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        
        Returns:
            Dict[str, Any]: ìˆ˜ì§‘ ê²°ê³¼
                - emails: ìƒˆ ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸ (ë‚´ë¶€ í¬ë§·)
                - messages: ìƒˆ ì±„íŒ… ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (ë‚´ë¶€ í¬ë§·)
                - raw_emails: ì›ë³¸ ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸
                - raw_messages: ì›ë³¸ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
                - success: ì„±ê³µ ì—¬ë¶€
                - error: ì˜¤ë¥˜ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        
        Example:
            >>> result = await data_source.collect_new_data_batch()
            >>> if result["success"]:
            >>>     print(f"ìƒˆ ì´ë©”ì¼: {len(result['emails'])}ê°œ")
        """
        mailbox = self.selected_persona.get("email_address")
        handle = (self.selected_persona.get("chat_handle") or "").strip()
        
        if not mailbox or not handle:
            return {
                "emails": [],
                "messages": [],
                "raw_emails": [],
                "raw_messages": [],
                "success": False,
                "error": "ì„ íƒëœ í˜ë¥´ì†Œë‚˜ì— email_address ë˜ëŠ” chat_handleì´ ì—†ìŠµë‹ˆë‹¤"
            }
        
        try:
            # ë³‘ë ¬ ìˆ˜ì§‘
            raw_emails, raw_messages = await self._collect_parallel(
                mailbox, handle.lower(), self.last_email_id, self.last_message_id
            )
            
            # ë°ì´í„° ë³€í™˜
            emails = [
                convert_email_to_internal_format(e, self.persona_by_email, mailbox)
                for e in raw_emails
            ]
            messages = [
                convert_message_to_internal_format(
                    m,
                    self.persona_by_handle,
                    selected_persona_handle=handle
                )
                for m in raw_messages
            ]
            
            # msg_id ê¸°ì¤€ ì¤‘ë³µ ì œê±° (TO/CC ì¤‘ë³µ ìˆ˜ì‹  ì²˜ë¦¬)
            seen_msg_ids = set()
            unique_emails = []
            for email in emails:
                msg_id = email.get("msg_id")
                if msg_id and msg_id not in seen_msg_ids:
                    seen_msg_ids.add(msg_id)
                    unique_emails.append(email)
                elif not msg_id:
                    unique_emails.append(email)
            
            if len(emails) != len(unique_emails):
                logger.info(
                    f"ğŸ” ì¤‘ë³µ ì´ë©”ì¼ ì œê±°: {len(emails)}ê°œ â†’ {len(unique_emails)}ê°œ "
                    f"({len(emails) - len(unique_emails)}ê°œ ì¤‘ë³µ)"
                )
            
            emails = unique_emails
            
            # last_id ì—…ë°ì´íŠ¸
            if raw_emails:
                self.last_email_id = max(e["id"] for e in raw_emails)
            if raw_messages:
                self.last_message_id = max(m["id"] for m in raw_messages)

            self._annotate_simulation_timestamps(emails)
            self._annotate_simulation_timestamps(messages)
            
            return {
                "emails": emails,
                "messages": messages,
                "raw_emails": raw_emails,
                "raw_messages": raw_messages,
                "success": True,
                "error": None
            }
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {
                "emails": [],
                "messages": [],
                "raw_emails": [],
                "raw_messages": [],
                "success": False,
                "error": str(e)
            }
    
    def get_personas(self) -> List[Dict[str, Any]]:
        """í˜ë¥´ì†Œë‚˜ ëª©ë¡ ë°˜í™˜"""
        return self.personas
    
    def get_source_type(self) -> str:
        """ì†ŒìŠ¤ íƒ€ì… ë°˜í™˜"""
        return "virtualoffice"
    
    def set_selected_persona(self, persona: Dict[str, Any]) -> None:
        """
        ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ë³€ê²½
        
        Args:
            persona: ìƒˆë¡œìš´ í˜ë¥´ì†Œë‚˜ ì •ë³´
        """
        self.selected_persona = persona
        # ì¦ë¶„ ìˆ˜ì§‘ ID ë¦¬ì…‹ (ìƒˆ í˜ë¥´ì†Œë‚˜ë¡œ ì „í™˜ ì‹œ ì²˜ìŒë¶€í„° ìˆ˜ì§‘)
        self.last_email_id = 0
        self.last_message_id = 0
        logger.info(f"í˜ë¥´ì†Œë‚˜ ë³€ê²½: {persona.get('name', 'Unknown')}")
    
    def get_selected_persona(self) -> Dict[str, Any]:
        """í˜„ì¬ ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ë°˜í™˜"""
        return self.selected_persona
    
    def reset_incremental_ids(self) -> None:
        """ì¦ë¶„ ìˆ˜ì§‘ ID ë¦¬ì…‹ (ì „ì²´ ì¬ìˆ˜ì§‘ ì‹œ ì‚¬ìš©)"""
        self.last_email_id = 0
        self.last_message_id = 0
        logger.info("ì¦ë¶„ ìˆ˜ì§‘ ID ë¦¬ì…‹")
    
    def cleanup_old_messages(self, max_count: Optional[int] = None) -> int:
        """
        ì˜¤ë˜ëœ ë©”ì‹œì§€ ì •ë¦¬
        
        ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
        ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìµœì‹  ë©”ì‹œì§€ë§Œ ìœ ì§€í•©ë‹ˆë‹¤.
        
        Args:
            max_count: ìœ ì§€í•  ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜ (ê¸°ë³¸ê°’: MAX_MESSAGES)
        
        Returns:
            int: ì‚­ì œëœ ë©”ì‹œì§€ ìˆ˜
        
        Example:
            >>> deleted = data_source.cleanup_old_messages(5000)
            >>> print(f"{deleted}ê°œ ë©”ì‹œì§€ ì‚­ì œë¨")
        """
        max_count = max_count or self.MAX_MESSAGES
        
        if len(self.cached_messages) <= max_count:
            return 0
        
        # ë‚ ì§œ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
        self.cached_messages.sort(key=lambda m: m.get("date", ""), reverse=True)
        
        # ì˜¤ë˜ëœ ë©”ì‹œì§€ ì‚­ì œ
        deleted_count = len(self.cached_messages) - max_count
        self.cached_messages = self.cached_messages[:max_count]
        
        logger.info(
            f"ë©”ì‹œì§€ ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ ì‚­ì œ, "
            f"{len(self.cached_messages)}ê°œ ìœ ì§€"
        )
        
        return deleted_count
    
    def add_messages_to_cache(self, messages: List[Dict[str, Any]]) -> None:
        """
        ë©”ì‹œì§€ë¥¼ ìºì‹œì— ì¶”ê°€í•˜ê³  í•„ìš”ì‹œ ìë™ ì •ë¦¬
        
        Args:
            messages: ì¶”ê°€í•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        self.cached_messages.extend(messages)
        
        # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìë™ ì •ë¦¬
        if len(self.cached_messages) > self.CLEANUP_THRESHOLD:
            logger.warning(
                f"ë©”ì‹œì§€ ìºì‹œ ì„ê³„ê°’ ì´ˆê³¼: {len(self.cached_messages)}ê°œ "
                f"(ì„ê³„ê°’: {self.CLEANUP_THRESHOLD})"
            )
            self.cleanup_old_messages()
    
    def get_cached_messages(self) -> List[Dict[str, Any]]:
        """
        ìºì‹œëœ ë©”ì‹œì§€ ë°˜í™˜
        
        Returns:
            List[Dict[str, Any]]: ìºì‹œëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        return self.cached_messages.copy()
    
    def clear_cache(self) -> None:
        """
        ë©”ì‹œì§€ ìºì‹œ ì™„ì „ ì‚­ì œ
        
        Example:
            >>> data_source.clear_cache()
        """
        count = len(self.cached_messages)
        self.cached_messages.clear()
        logger.info(f"ë©”ì‹œì§€ ìºì‹œ ì‚­ì œ: {count}ê°œ")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        ìºì‹œ í†µê³„ ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: ìºì‹œ í†µê³„
                - total_messages: ì´ ë©”ì‹œì§€ ìˆ˜
                - max_messages: ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜
                - cleanup_threshold: ì •ë¦¬ ì„ê³„ê°’
                - usage_percent: ì‚¬ìš©ë¥  (%)
                - needs_cleanup: ì •ë¦¬ í•„ìš” ì—¬ë¶€
        
        Example:
            >>> stats = data_source.get_cache_stats()
            >>> print(f"ì‚¬ìš©ë¥ : {stats['usage_percent']:.1f}%")
        """
        total = len(self.cached_messages)
        usage_percent = (total / self.MAX_MESSAGES) * 100 if self.MAX_MESSAGES > 0 else 0
        
        return {
            "total_messages": total,
            "max_messages": self.MAX_MESSAGES,
            "cleanup_threshold": self.CLEANUP_THRESHOLD,
            "usage_percent": usage_percent,
            "needs_cleanup": total > self.CLEANUP_THRESHOLD
        }
    
    def get_simulation_status_cached(self, force_refresh: bool = False) -> Optional[Dict[str, Any]]:
        """
        ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ì¡°íšŒ (ìºì‹± ì ìš©)
        
        TTL(Time To Live) ê¸°ë°˜ ìºì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë¶ˆí•„ìš”í•œ API í˜¸ì¶œì„ ì¤„ì…ë‹ˆë‹¤.
        ê¸°ë³¸ TTLì€ 2ì´ˆì…ë‹ˆë‹¤.
        
        Args:
            force_refresh: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ê°•ì œ ê°±ì‹ 
        
        Returns:
            Optional[Dict[str, Any]]: ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ë˜ëŠ” None (ì˜¤ë¥˜ ì‹œ)
        
        Example:
            >>> status = data_source.get_simulation_status_cached()
            >>> if status:
            >>>     print(f"í˜„ì¬ í‹±: {status['current_tick']}")
        """
        current_time = time.time()
        
        # ìºì‹œ ìœ íš¨ì„± í™•ì¸
        if not force_refresh and self._cached_sim_status:
            cache_age = current_time - self._sim_status_cache_time
            if cache_age < self._sim_status_cache_ttl:
                logger.debug(f"ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ìºì‹œ ì‚¬ìš© (age: {cache_age:.2f}ì´ˆ)")
                return self._cached_sim_status
        
        # ìºì‹œ ë§Œë£Œ ë˜ëŠ” ê°•ì œ ê°±ì‹ 
        try:
            status = self.client.get_simulation_status()
            self._cached_sim_status = status.to_dict() if hasattr(status, 'to_dict') else status
            self._sim_status_cache_time = current_time
            logger.debug("ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ìºì‹œ ê°±ì‹ ")
            return self._cached_sim_status
        except Exception as e:
            logger.error(f"ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ìºì‹œ ë°˜í™˜ (ìˆìœ¼ë©´)
            return self._cached_sim_status
    
    def invalidate_sim_status_cache(self) -> None:
        """
        ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ìºì‹œ ë¬´íš¨í™”
        
        Example:
            >>> data_source.invalidate_sim_status_cache()
        """
        self._cached_sim_status = None
        self._sim_status_cache_time = 0
        logger.debug("ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ìºì‹œ ë¬´íš¨í™”")
    
    def set_sim_status_cache_ttl(self, ttl: float) -> None:
        """
        ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ìºì‹œ TTL ì„¤ì •
        
        Args:
            ttl: TTL (ì´ˆ)
        
        Example:
            >>> data_source.set_sim_status_cache_ttl(5.0)  # 5ì´ˆë¡œ ë³€ê²½
        """
        if ttl <= 0:
            logger.warning(f"ì˜ëª»ëœ TTL: {ttl}ì´ˆ. ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        old_ttl = self._sim_status_cache_ttl
        self._sim_status_cache_ttl = ttl
        logger.info(f"ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ìºì‹œ TTL ë³€ê²½: {old_ttl}ì´ˆ â†’ {ttl}ì´ˆ")
    
    def refresh_persona_cache(self) -> bool:
        """
        í˜ë¥´ì†Œë‚˜ ìºì‹œ ê°•ì œ ê°±ì‹ 
        
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        
        Example:
            >>> if data_source.refresh_persona_cache():
            >>>     print("í˜ë¥´ì†Œë‚˜ ìºì‹œ ê°±ì‹  ì„±ê³µ")
        """
        try:
            self._load_personas()
            return True
        except Exception as e:
            logger.error(f"í˜ë¥´ì†Œë‚˜ ìºì‹œ ê°±ì‹  ì‹¤íŒ¨: {e}")
            return False
    def _apply_time_filter(self, messages: List[Dict[str, Any]], time_range: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ì‹œê°„ ë²”ìœ„ í•„í„°ë§ ì ìš©
        
        Args:
            messages: í•„í„°ë§í•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            time_range: ì‹œê°„ ë²”ìœ„ {"start": datetime, "end": datetime}
            
        Returns:
            í•„í„°ë§ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        try:
            start_time = time_range.get("start")
            end_time = time_range.get("end")
            
            if not start_time or not end_time:
                logger.warning("ì‹œê°„ ë²”ìœ„ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤")
                return messages
            
            # UTCë¡œ ë³€í™˜
            if start_time.tzinfo is None:
                start_time = start_time.replace(tzinfo=timezone.utc)
            else:
                start_time = start_time.astimezone(timezone.utc)
                
            if end_time.tzinfo is None:
                end_time = end_time.replace(tzinfo=timezone.utc)
            else:
                end_time = end_time.astimezone(timezone.utc)
            
            filtered_messages = []
            
            for message in messages:
                message_time = self._parse_message_time(message)
                if message_time and start_time <= message_time <= end_time:
                    filtered_messages.append(message)
            
            original_count = len(messages)
            filtered_count = len(filtered_messages)
            
            logger.info(f"â° ì‹œê°„ í•„í„°ë§ ê²°ê³¼: {original_count}ê°œ â†’ {filtered_count}ê°œ")
            
            return filtered_messages
            
        except Exception as e:
            logger.error(f"ì‹œê°„ í•„í„°ë§ ì˜¤ë¥˜: {e}")
            return messages  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°˜í™˜
    
    def _parse_message_time(self, message: Dict[str, Any]) -> Optional[datetime]:
        """ë©”ì‹œì§€ì—ì„œ ì‹œê°„ ì •ë³´ íŒŒì‹±
        
        Args:
            message: ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            íŒŒì‹±ëœ datetime (UTC) ë˜ëŠ” None
        """
        try:
            try:
                import dateutil.parser
            except ImportError:
                logger.warning("python-dateutil íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ datetime íŒŒì‹±ë§Œ ì‚¬ìš©")
                dateutil = None
            
            # ë‹¤ì–‘í•œ ì‹œê°„ í•„ë“œ ì‹œë„
            time_fields = ['date', 'timestamp', 'sent_at', 'created_at']
            
            for field in time_fields:
                if field in message and message[field]:
                    time_value = message[field]
                    
                    if isinstance(time_value, datetime):
                        # ì´ë¯¸ datetime ê°ì²´
                        if time_value.tzinfo is None:
                            return time_value.replace(tzinfo=timezone.utc)
                        return time_value.astimezone(timezone.utc)
                    
                    elif isinstance(time_value, str):
                        # ë¬¸ìì—´ íŒŒì‹±
                        try:
                            if dateutil:
                                dt = dateutil.parser.parse(time_value)
                            else:
                                # ê¸°ë³¸ ISO í˜•ì‹ë§Œ ì§€ì›
                                dt = datetime.fromisoformat(time_value.replace('Z', '+00:00'))
                            
                            if dt.tzinfo is None:
                                dt = dt.replace(tzinfo=timezone.utc)
                            return dt.astimezone(timezone.utc)
                        except Exception:
                            continue
                    
                    elif isinstance(time_value, (int, float)):
                        # íƒ€ì„ìŠ¤íƒ¬í”„
                        return datetime.fromtimestamp(time_value, tz=timezone.utc)
            
            return None
            
        except Exception as e:
            logger.debug(f"ë©”ì‹œì§€ ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
