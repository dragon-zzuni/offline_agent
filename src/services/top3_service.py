# -*- coding: utf-8 -*-
"""
Top3 TODO ì„ ì • ë° ê·œì¹™ ê´€ë¦¬ ì„œë¹„ìŠ¤ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)

TODO í•­ëª©ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ê³„ì‚°í•˜ê³  Top3ë¥¼ ìë™ìœ¼ë¡œ ì„ ì •í•©ë‹ˆë‹¤.
ìì—°ì–´ ê·œì¹™ í•´ì„ ë° LLM ê¸°ë°˜ Top3 ì„ ì •ì„ ì§€ì›í•©ë‹ˆë‹¤.

ì´ í´ë˜ìŠ¤ëŠ” ë‹¤ìŒ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì¡°ìœ¨í•©ë‹ˆë‹¤:
- Top3LLMSelector: LLM ê¸°ë°˜ Top3 ì„ ì •
- Top3ScoreCalculator: ì ìˆ˜ ê¸°ë°˜ Top3 ì„ ì • (í´ë°±)
- Top3CacheManager: ì„ ì • ê²°ê³¼ ìºì‹±
"""
import os
import json
import logging
import re
from copy import deepcopy
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Tuple, Set

logger = logging.getLogger(__name__)

# Top-3 ê·œì¹™ ê¸°ë³¸ê°’
TOP3_RULE_DEFAULT = {
    "priority_high": 3.0,
    "priority_medium": 2.0,
    "priority_low": 1.0,
    "deadline_emphasis": 24.0,
    "deadline_base": 1.0,
    "evidence_per_item": 0.1,
    "evidence_max_bonus": 0.5,
    "recipient_type_cc_penalty": 0.7,
}

# ì—”í‹°í‹° ê·œì¹™ ê¸°ë³¸ê°’
ENTITY_RULES_DEFAULT = {
    "requester": {},
    "type": {},
}


class Top3Service:
    """Top3 TODO ì„ ì • ë° ê·œì¹™ ê´€ë¦¬ ì„œë¹„ìŠ¤ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)"""
    
    def __init__(
        self, 
        config_path: Optional[str] = None, 
        people_data: Optional[List[Dict]] = None, 
        vdos_connector=None,
        persona_cache_service=None
    ):
        """
        Args:
            config_path: ê·œì¹™ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            people_data: ì‚¬ëŒ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ì´ë©”ì¼â†’ì´ë¦„ ë§¤í•‘ìš©)
            vdos_connector: VDOSConnector ì¸ìŠ¤í„´ìŠ¤ (ì‹¤ì‹œê°„ people ë°ì´í„°ìš©)
            persona_cache_service: PersonaTodoCacheService ì¸ìŠ¤í„´ìŠ¤ (TODO ìºì‹œìš©)
        """
        # VDOS DB ìœ„ì¹˜ì— ì„¤ì • íŒŒì¼ ì €ì¥
        if config_path is None:
            if vdos_connector and vdos_connector.is_available:
                # vdos.dbì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ì €ì¥
                vdos_dir = os.path.dirname(vdos_connector.vdos_db_path)
                config_path = os.path.join(vdos_dir, "top3_config.json")
            else:
                # í´ë°±: ê¸°ë³¸ ê²½ë¡œ
                config_path = os.path.join("data", "top3_config.json")
        
        self.config_path = config_path
        self._rules = deepcopy(TOP3_RULE_DEFAULT)
        self._entity_rules = deepcopy(ENTITY_RULES_DEFAULT)
        self._last_instruction = ""
        self._last_reasoning = ""  # ë§ˆì§€ë§‰ ì„ ì • ì´ìœ  (í•œêµ­ì–´)
        self._vdos_connector = vdos_connector
        self._persona_cache_service = persona_cache_service
        
        # ì´ë©”ì¼ â†’ ì´ë¦„ ë§¤í•‘ êµ¬ì¶•
        self._email_to_name = {}
        
        # people_data ë¡œë“œ ìš°ì„ ìˆœìœ„: 1) íŒŒë¼ë¯¸í„°, 2) VDOS, 3) JSON íŒŒì¼
        if people_data is None:
            if vdos_connector and vdos_connector.is_available:
                people_data = vdos_connector.get_people()
                logger.info(f"[Top3Service] VDOSì—ì„œ people ë°ì´í„° ë¡œë“œ: {len(people_data)}ëª…")
            else:
                people_data = self._load_people_data()
        
        if people_data:
            for person in people_data:
                email = person.get("email_address", "")
                name = person.get("name", "")
                if email and name:
                    self._email_to_name[email.lower()] = name
                    logger.debug(f"[Top3Service] ì´ë©”ì¼ ë§¤í•‘: {email} â†’ {name}")
        
        logger.info(f"[Top3Service] ì´ˆê¸°í™” ì™„ë£Œ: {len(self._email_to_name)}ê°œ ì´ë©”ì¼ ë§¤í•‘")
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (lazy loading)
        self._llm_selector = None
        self._score_calculator = None
        self._cache_manager = None
        self._llm_enabled = True  # LLM ì‚¬ìš© ì—¬ë¶€
        self._llm_failure_count = 0  # ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜
        self._max_llm_failures = 3  # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜
        
        # ì €ì¥ëœ ê·œì¹™ ë¡œë“œ
        self._load_rules()
    
    def _get_llm_selector(self):
        """LLM Selector lazy initialization"""
        if self._llm_selector is None:
            from .top3_llm_selector import Top3LLMSelector
            from .llm_client import LLMClient
            
            llm_client = LLMClient()
            cache_manager = self._get_cache_manager()
            
            self._llm_selector = Top3LLMSelector(
                llm_client=llm_client,
                cache_manager=cache_manager,
                email_to_name=self._email_to_name
            )
            logger.debug("[Top3Service] LLM Selector ì´ˆê¸°í™” ì™„ë£Œ")
        
        return self._llm_selector
    
    def _get_score_calculator(self):
        """Score Calculator lazy initialization"""
        if self._score_calculator is None:
            from .top3_score_calculator import Top3ScoreCalculator
            
            self._score_calculator = Top3ScoreCalculator(
                rules=self._rules,
                entity_rules=self._entity_rules,
                email_to_name=self._email_to_name
            )
            logger.debug("[Top3Service] Score Calculator ì´ˆê¸°í™” ì™„ë£Œ")
        
        return self._score_calculator
    
    def _get_cache_manager(self):
        """Cache Manager lazy initialization"""
        if self._cache_manager is None:
            from .top3_cache_manager import Top3CacheManager
            
            self._cache_manager = Top3CacheManager(ttl_seconds=300)  # 5ë¶„ TTL
            logger.debug("[Top3Service] Cache Manager ì´ˆê¸°í™” ì™„ë£Œ")
        
        return self._cache_manager
    
    def _load_people_data(self) -> List[Dict]:
        """people ë°ì´í„° ìë™ ë¡œë“œ"""
        try:
            # people íŒŒì¼ ì°¾ê¸° (ì ˆëŒ€ ê²½ë¡œ ë° ìƒëŒ€ ê²½ë¡œ ëª¨ë‘ ì‹œë„)
            data_dir = os.path.dirname(self.config_path)
            
            # ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹ˆë©´ í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
            if not os.path.isabs(data_dir):
                data_dir = os.path.abspath(data_dir)
            
            logger.debug(f"[Top3Service] people ë°ì´í„° ê²€ìƒ‰ ê²½ë¡œ: {data_dir}")
            
            if not os.path.exists(data_dir):
                logger.warning(f"[Top3Service] ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_dir}")
                return []
            
            people_files = [f for f in os.listdir(data_dir) if f.startswith("people_") and f.endswith(".json")]
            
            if not people_files:
                logger.warning(f"[Top3Service] people ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ê²½ë¡œ: {data_dir})")
                return []
            
            # ê°€ì¥ ìµœì‹  íŒŒì¼ ì‚¬ìš©
            people_file = sorted(people_files)[-1]
            people_path = os.path.join(data_dir, people_file)
            
            logger.debug(f"[Top3Service] people íŒŒì¼ ë¡œë“œ ì‹œë„: {people_path}")
            
            with open(people_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                people_list = data.get("people", [])
                logger.info(f"[Top3Service] people ë°ì´í„° ë¡œë“œ ì„±ê³µ: {people_file} ({len(people_list)}ëª…)")
                return people_list
        except Exception as e:
            logger.error(f"[Top3Service] people ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return []
    
    def get_rules(self) -> Dict[str, float]:
        """í˜„ì¬ ê·œì¹™ ë°˜í™˜"""
        return dict(self._rules)
    
    def get_entity_rules(self) -> Dict[str, Dict[str, float]]:
        """í˜„ì¬ ì—”í‹°í‹° ê·œì¹™ ë°˜í™˜"""
        return {k: dict(v) for k, v in self._entity_rules.items()}
    
    def get_last_instruction(self) -> str:
        """ë§ˆì§€ë§‰ ìì—°ì–´ ì§€ì‹œì‚¬í•­ ë°˜í™˜"""
        return self._last_instruction
    
    def set_rules(self, new_rules: Dict[str, float]) -> None:
        """ê·œì¹™ ì„¤ì •"""
        for key, default in TOP3_RULE_DEFAULT.items():
            value = new_rules.get(key)
            if value is None:
                continue
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if not isinstance(value, (int, float)):
                continue
            
            # ë²”ìœ„ ì œí•œ
            if key.startswith("priority_"):
                if value < 0:
                    value = 0.0
                if value > 10:
                    value = 10.0
            elif key == "deadline_emphasis":
                if value < 0:
                    value = 0.0
                if value > 100:
                    value = 100.0
            elif key == "deadline_base":
                if value < 0:
                    value = 0.0
                if value > 10:
                    value = 10.0
            elif key == "evidence_per_item":
                if value < 0:
                    value = 0.0
                if value > 1:
                    value = 1.0
            elif key == "evidence_max_bonus":
                if value < 0:
                    value = 0.0
            elif key == "recipient_type_cc_penalty":
                if value < 0:
                    value = 0.0
                if value > 1:
                    value = 1.0
            
            self._rules[key] = value
        
        # ScoreCalculator ì—…ë°ì´íŠ¸
        if self._score_calculator is not None:
            self._score_calculator.update_rules(self._rules)
    
    def update_entity_rules(self, new_rules: Optional[Dict[str, Dict[str, float]]], reset: bool = False) -> None:
        """ì—”í‹°í‹° ê·œì¹™ ì—…ë°ì´íŠ¸"""
        if reset:
            for cat in ENTITY_RULES_DEFAULT:
                self._entity_rules[cat].clear()
        
        if not new_rules:
            return
        
        for category, mapping in new_rules.items():
            if category not in self._entity_rules:
                continue
            
            dest = self._entity_rules[category]
            for key, value in (mapping or {}).items():
                if value is None:
                    dest.pop(key, None)
                    continue
                
                if not isinstance(value, (int, float)):
                    continue
                
                # ë²”ìœ„ ì œí•œ
                if value < -10:
                    value = -10.0
                if value > 10:
                    value = 10.0
                
                dest[key] = value
                
                # í•œêµ­ì–´ ì´ë¦„ ë³€í˜• ì²˜ë¦¬
                if category == "requester":
                    from .top3_korean_utils import normalize_korean_name, generate_korean_name_variations
                    
                    normalized = normalize_korean_name(key)
                    if normalized != key:
                        dest[normalized] = max(dest.get(normalized, 0.0), value)
                    
                    variations = generate_korean_name_variations(key)
                    for variation in variations:
                        if variation not in dest:
                            dest[variation] = value
                        else:
                            dest[variation] = max(dest.get(variation, 0.0), value)
        
        # ScoreCalculator ì—…ë°ì´íŠ¸
        if self._score_calculator is not None:
            self._score_calculator.update_entity_rules(self._entity_rules)
    
    def calculate_score(self, todo: Dict) -> float:
        """TODO í•­ëª©ì˜ ì ìˆ˜ ê³„ì‚° (ScoreCalculatorë¡œ ìœ„ì„)"""
        score_calculator = self._get_score_calculator()
        return score_calculator.calculate_score(todo)
    

    
    def pick_top3(self, items: List[Dict], use_llm: bool = True, simulation_time: Optional[datetime] = None) -> Set[str]:
        """Top3 TODO ì„ ì • (LLM ë˜ëŠ” ì ìˆ˜ ê¸°ë°˜)
        
        Args:
            items: TODO í•­ëª© ë¦¬ìŠ¤íŠ¸
            use_llm: LLM ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            simulation_time: ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ (Noneì´ë©´ í˜„ì¬ ì‹œê°„ ì‚¬ìš©)
        
        Returns:
            Set[str]: Top3 TODO ID ì§‘í•©
        
        ì„ ì • ë°©ì‹:
        1. ì¤‘ë³µ ì œê±° (ê°™ì€ source_messageëŠ” 1ê°œë§Œ)
        2. ìì—°ì–´ ê·œì¹™ì´ ìˆê³  LLMì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ LLM ì„ ì • ì‹œë„
        3. LLM ì‹¤íŒ¨ ì‹œ ì ìˆ˜ ê¸°ë°˜ ì„ ì •ìœ¼ë¡œ í´ë°±
        4. ìì—°ì–´ ê·œì¹™ì´ ì—†ìœ¼ë©´ ì ìˆ˜ ê¸°ë°˜ ì„ ì •
        """
        # 1. statusê°€ doneì´ ì•„ë‹Œ ê²ƒë§Œ í›„ë³´
        candidates = [x for x in items if (x.get("status") or "pending") not in ("done",)]
        
        if not candidates:
            logger.info("[Top3Service] í›„ë³´ TODOê°€ ì—†ìŠµë‹ˆë‹¤")
            return set()
        
        # 2. ì¤‘ë³µ ì œê±°ëŠ” TodoPanelì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨ (ì œëª© í¬í•¨í•œ identity ê¸°ë°˜)
        # ì—¬ê¸°ì„œ ì¶”ê°€ ì¤‘ë³µ ì œê±°ë¥¼ í•˜ë©´ ê°™ì€ ë©”ì‹œì§€ì—ì„œ ë‚˜ì˜¨ ì„œë¡œ ë‹¤ë¥¸ TODOë“¤ì´ ì œê±°ë¨
        # candidates = self._deduplicate_by_source(candidates)
        
        logger.info(f"[Top3Service] ğŸ“Š Top3 í›„ë³´: {len(candidates)}ê°œ TODO")
        
        # 2. ìì—°ì–´ ê·œì¹™ í™•ì¸ (entity_rules ë˜ëŠ” last_instructionì´ ìˆìœ¼ë©´ ìì—°ì–´ ê·œì¹™ ìˆìŒ)
        has_natural_rules = bool(
            self._last_instruction or  # ìì—°ì–´ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê·œì¹™ ìˆìŒ
            self._entity_rules.get("requester") or 
            self._entity_rules.get("keyword") or 
            self._entity_rules.get("type")
        )
        
        # 3. LLM ì„ ì • ì‹œë„ (ì¡°ê±´: ìì—°ì–´ ê·œì¹™ ìˆìŒ + LLM í™œì„±í™” + use_llm=True)
        if has_natural_rules and self._llm_enabled and use_llm:
            logger.info(f"[Top3Service] ğŸ¤– LLM ëª¨ë“œ: ìì—°ì–´ ê·œì¹™ ê¸°ë°˜ Top3 ì„ ì • ì‹œë„")
            
            try:
                llm_selector = self._get_llm_selector()
                
                # LLM ì„ ì • ì‹¤í–‰
                top3_ids = llm_selector.select_top3(
                    todos=candidates,
                    natural_rule=self._last_instruction,
                    entity_rules=self._entity_rules,
                    simulation_time=simulation_time
                )
                
                if top3_ids:
                    # LLM ì„ ì • ì„±ê³µ
                    self._llm_failure_count = 0  # ì‹¤íŒ¨ ì¹´ìš´í„° ë¦¬ì…‹
                    # ì„ ì • ì´ìœ  ì €ì¥
                    self._last_reasoning = llm_selector.last_reasoning
                    logger.info(f"[Top3Service] âœ… LLM ì„ ì • ì„±ê³µ: {len(top3_ids)}ê°œ ì„ ì •")
                    return top3_ids
                else:
                    # LLMì´ ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ê·œì¹™ì— ë§ëŠ” TODO ì—†ìŒ)
                    logger.warning(f"[Top3Service] âš ï¸ LLMì´ ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ê·œì¹™ì— ë§ëŠ” TODO ì—†ìŒ)")
                    return set()
            
            except Exception as e:
                # LLM ì„ ì • ì‹¤íŒ¨ - í´ë°±ìœ¼ë¡œ ì „í™˜
                self._llm_failure_count += 1
                logger.error(f"[Top3Service] âŒ LLM ì„ ì • ì‹¤íŒ¨ ({self._llm_failure_count}/{self._max_llm_failures}): {e}")
                
                # ì—°ì† ì‹¤íŒ¨ ì‹œ LLM ë¹„í™œì„±í™”
                if self._llm_failure_count >= self._max_llm_failures:
                    self._llm_enabled = False
                    logger.warning(
                        f"[Top3Service] ğŸš« LLM ì—°ì† {self._max_llm_failures}íšŒ ì‹¤íŒ¨ - "
                        f"ì ìˆ˜ ê¸°ë°˜ ì„ ì •ìœ¼ë¡œ ìë™ ì „í™˜ë©ë‹ˆë‹¤"
                    )
                
                # ì ìˆ˜ ê¸°ë°˜ ì„ ì •ìœ¼ë¡œ í´ë°±
                logger.info("[Top3Service] ğŸ“Š í´ë°±: ì ìˆ˜ ê¸°ë°˜ ì„ ì •ìœ¼ë¡œ ì „í™˜")
        
        # 4. ì ìˆ˜ ê¸°ë°˜ ì„ ì • (í´ë°± ë˜ëŠ” ê¸°ë³¸ ëª¨ë“œ)
        if has_natural_rules:
            # ìì—°ì–´ ê·œì¹™ì´ ìˆìœ¼ë©´ ê·œì¹™ ë§¤ì¹­ TODOë§Œ ì„ ì •
            logger.info(f"[Top3Service] ğŸ”’ ê°•ì œ ëª¨ë“œ: ìì—°ì–´ ê·œì¹™ì— ë§ëŠ” TODOë§Œ ì„ ì •")
            
            score_calculator = self._get_score_calculator()
            top3_ids = score_calculator.select_top3_with_rules(
                candidates=candidates,
                entity_rules=self._entity_rules
            )
            
            if not top3_ids:
                logger.warning(f"[Top3Service] âš ï¸ ê·œì¹™ì— ë§ëŠ” TODOê°€ ì—†ìŒ (ì „ì²´ {len(candidates)}ê°œ ì¤‘)")
            else:
                logger.info(f"[Top3Service] âœ… ê°•ì œ ëª¨ë“œ ì™„ë£Œ: {len(top3_ids)}ê°œ ì„ ì •")
            
            return top3_ids
        else:
            # ìì—°ì–´ ê·œì¹™ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ì ìˆ˜ ê¸°ë°˜ ì„ ì •
            logger.info(f"[Top3Service] ğŸ“Š ì¼ë°˜ ëª¨ë“œ: ì ìˆ˜ ê¸°ë°˜ Top3 ì„ ì •")
            
            score_calculator = self._get_score_calculator()
            top3_ids = score_calculator.select_top3(candidates)
            
            logger.info(f"[Top3Service] âœ… ì¼ë°˜ ëª¨ë“œ ì™„ë£Œ: {len(candidates)}ê°œ ì¤‘ {len(top3_ids)}ê°œ ì„ ì •")
            return top3_ids
    
    def enable_llm(self) -> None:
        """LLM ì„ ì • í™œì„±í™”"""
        self._llm_enabled = True
        self._llm_failure_count = 0
        logger.info("[Top3Service] LLM ì„ ì • í™œì„±í™”")
    
    def disable_llm(self) -> None:
        """LLM ì„ ì • ë¹„í™œì„±í™”"""
        self._llm_enabled = False
        logger.info("[Top3Service] LLM ì„ ì • ë¹„í™œì„±í™”")
    
    def is_llm_enabled(self) -> bool:
        """LLM ì„ ì • í™œì„±í™” ì—¬ë¶€ í™•ì¸"""
        return self._llm_enabled
    
    def describe_rules(self) -> str:
        """í˜„ì¬ ê·œì¹™ì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…"""
        rules = self.get_rules()
        entity_rules = self.get_entity_rules()
        
        # ìì—°ì–´ ê·œì¹™ í™•ì¸
        has_natural_rules = bool(entity_rules.get("requester") or 
                                 entity_rules.get("keyword") or 
                                 entity_rules.get("type"))
        
        parts = []
        
        # LLM ìƒíƒœ í‘œì‹œ
        if has_natural_rules:
            if self._llm_enabled:
                parts.append("ğŸ¤– LLM ëª¨ë“œ: ìì—°ì–´ ê·œì¹™ ê¸°ë°˜ ì§€ëŠ¥í˜• ì„ ì •")
            else:
                parts.append("ğŸ”’ ê°•ì œ ëª¨ë“œ: ìì—°ì–´ ê·œì¹™ì— ë§ëŠ” TODOë§Œ Top3 í‘œì‹œ (LLM ë¹„í™œì„±í™”)")
            
            if entity_rules.get("requester"):
                requester_list = ", ".join(list(entity_rules["requester"].keys())[:5])
                if len(entity_rules["requester"]) > 5:
                    requester_list += f" ì™¸ {len(entity_rules['requester']) - 5}ëª…"
                parts.append(f"  â€¢ ìš”ì²­ì: {requester_list}")
            
            if entity_rules.get("keyword"):
                keyword_list = ", ".join(list(entity_rules["keyword"].keys())[:5])
                if len(entity_rules["keyword"]) > 5:
                    keyword_list += f" ì™¸ {len(entity_rules['keyword']) - 5}ê°œ"
                parts.append(f"  â€¢ í‚¤ì›Œë“œ: {keyword_list}")
            
            if entity_rules.get("type"):
                type_list = ", ".join(list(entity_rules["type"].keys())[:5])
                if len(entity_rules["type"]) > 5:
                    type_list += f" ì™¸ {len(entity_rules['type']) - 5}ê°œ"
                parts.append(f"  â€¢ íƒ€ì…: {type_list}")
        else:
            parts.append("ğŸ“Š ì¼ë°˜ ëª¨ë“œ: ì ìˆ˜ ê¸°ë°˜ Top3 ì„ ì •")
        
        parts.extend([
            f"ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ H/M/L: {rules.get('priority_high',0):.2f}/{rules.get('priority_medium',0):.2f}/{rules.get('priority_low',0):.2f}",
            f"ë°ë“œë¼ì¸ ê°•ì¡°: {rules.get('deadline_emphasis',0):.1f}ì‹œê°„",
            f"ê·¼ê±°ë‹¹ ê°€ì¤‘ì¹˜: {rules.get('evidence_per_item',0):.2f} (ìµœëŒ€ {rules.get('evidence_max_bonus',0):.2f})",
            f"CC/BCC í˜ë„í‹°: {rules.get('recipient_type_cc_penalty',0):.2f}",
        ])
        
        return "\n".join(parts)
    
    def apply_natural_language_rules(self, text: str, reset: bool = False) -> Tuple[str, str]:
        """
        ìì—°ì–´ ì§€ì‹œì‚¬í•­ì„ ê·œì¹™ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ìì—°ì–´ ì§€ì‹œì‚¬í•­
            reset: ê·œì¹™ ì´ˆê¸°í™” ì—¬ë¶€
            
        Returns:
            Tuple[str, str]: (ê²°ê³¼ ë©”ì‹œì§€, í˜„ì¬ ê·œì¹™ ì„¤ëª…)
        """
        cleaned_text = text.strip()
        
        if reset or not cleaned_text:
            self._last_instruction = "" if reset else cleaned_text
            self.set_rules(TOP3_RULE_DEFAULT)
            self.update_entity_rules({}, reset=True)
            self._save_rules()
            
            # ì´ˆê¸°í™” ì‹œ ìºì‹œ ì‚­ì œ
            if self._llm_selector:
                self._llm_selector.cache_manager.clear()
                logger.info("[Top3Service] ê·œì¹™ ì´ˆê¸°í™”ë¡œ ì¸í•œ ìºì‹œ ì‚­ì œ")
            
            logger.info("[Top3Service] rules reset by user input")
            return "ê·œì¹™ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.", self.describe_rules()
        
        # LLM íŒŒì‹± ë¨¼ì € ì‹œë„ (ë” ì •í™•í•¨)
        logger.info(f"[Top3Service] ìì—°ì–´ ê·œì¹™ íŒŒì‹± ì‹œì‘: '{cleaned_text[:50]}...'")
        parsed, llm_message = self._try_llm_parse_rules(cleaned_text)
        
        if parsed:
            logger.info(f"[Top3Service] LLM íŒŒì‹± ì„±ê³µ: {llm_message}")
        else:
            # LLM ì‹¤íŒ¨ ì‹œ íœ´ë¦¬ìŠ¤í‹± íŒŒì‹±ìœ¼ë¡œ í´ë°±
            logger.warning(f"[Top3Service] LLM íŒŒì‹± ì‹¤íŒ¨, íœ´ë¦¬ìŠ¤í‹± íŒŒì‹±ìœ¼ë¡œ í´ë°±")
            parsed, heuristic_note = self._heuristic_parse_rules(cleaned_text)
            
            if parsed:
                logger.info(f"[Top3Service] íœ´ë¦¬ìŠ¤í‹± íŒŒì‹± ì„±ê³µ: {heuristic_note}")
                llm_message = heuristic_note
            else:
                logger.warning(f"[Top3Service] íœ´ë¦¬ìŠ¤í‹± íŒŒì‹±ë„ ì‹¤íŒ¨")
        
        if not parsed:
            msg = "ê·œì¹™ì„ í•´ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”."
            if llm_message:
                msg += f" (ìƒì„¸: {llm_message})"
            logger.warning(f"[Top3Service] ê·œì¹™ íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {msg}")
            return msg, self.describe_rules()
        
        # ê·œì¹™ ì ìš©
        if parsed.get("reset"):
            self._last_instruction = ""
            self.set_rules(TOP3_RULE_DEFAULT)
            self.update_entity_rules({}, reset=True)
            self._save_rules()
            return "ê·œì¹™ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.", self.describe_rules()
        
        # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        weights = parsed.get("weights")
        if weights:
            self.set_rules(weights)
        
        # ì—”í‹°í‹° ê·œì¹™ ì—…ë°ì´íŠ¸
        entities = parsed.get("entities")
        if entities:
            self.update_entity_rules(entities, reset=False)
        
        self._last_instruction = cleaned_text
        self._save_rules()
        
        # ê·œì¹™ ë³€ê²½ ì‹œ ìºì‹œ ì‚­ì œ (ìƒˆë¡œìš´ ê·œì¹™ìœ¼ë¡œ ì¬ì„ ì •í•˜ê¸° ìœ„í•´)
        if self._llm_selector:
            self._llm_selector.cache_manager.clear()
            logger.info("[Top3Service] ê·œì¹™ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ìºì‹œ ì‚­ì œ")
        
        result_msg = "ê·œì¹™ì„ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤."
        if llm_message:
            result_msg += f" ({llm_message})"
        
        return result_msg, self.describe_rules()
    
    def _try_llm_parse_rules(self, text: str) -> Tuple[Optional[Dict], str]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ìì—°ì–´ ê·œì¹™ íŒŒì‹±"""
        # LLM ì„¤ì • í™•ì¸
        provider = os.environ.get("LLM_PROVIDER", "openai").lower()
        
        if provider == "openai":
            api_key = os.environ.get("OPENAI_API_KEY")
            url = "https://api.openai.com/v1/chat/completions"
            model = "gpt-4o-mini"
        elif provider == "azure":
            api_key = os.environ.get("AZURE_OPENAI_KEY")
            endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT", "").rstrip("/")
            deployment = os.environ.get("AZURE_OPENAI_DEPLOYMENT", "gpt-4o-mini")
            api_version = os.environ.get("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
            url = f"{endpoint}/openai/deployments/{deployment}/chat/completions?api-version={api_version}"
            model = deployment
        elif provider == "openrouter":
            api_key = os.environ.get("OPENROUTER_API_KEY")
            url = "https://openrouter.ai/api/v1/chat/completions"
            model = "openai/gpt-4o-mini"
        else:
            return None, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM ì œê³µì: {provider}"
        
        if not api_key:
            return None, "LLM API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = """ë‹¹ì‹ ì€ TODO ìš°ì„ ìˆœìœ„ ê·œì¹™ì„ í•´ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ì§€ì‹œì‚¬í•­ì„ JSON í˜•ì‹ì˜ ê·œì¹™ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

**ì¤‘ìš”: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.**

**ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œì— ë”°ë¥¸ ë³´ë„ˆìŠ¤ ì ìˆ˜ ê°€ì´ë“œ**
- "ìµœìš°ì„ ", "ë¬´ì¡°ê±´", "í•­ìƒ", "ë°˜ë“œì‹œ", "ê°€ì¥ ë¨¼ì €", "ì œì¼": requester ë³´ë„ˆìŠ¤ 8.0~10.0 (ë§¤ìš° ë†’ê²Œ!)
- "ìš°ì„ ", "ì¤‘ìš”", "ë¨¼ì €": requester ë³´ë„ˆìŠ¤ 4.0~6.0
- "ë³´í†µ", "ì¼ë°˜": requester ë³´ë„ˆìŠ¤ 2.0~3.0
- "ë‚®ìŒ", "ë‚˜ì¤‘ì—": requester ë³´ë„ˆìŠ¤ 0.5~1.5

**ì‘ë‹µ í˜•ì‹:**
{
  "reset": false,
  "weights": {
    "priority_high": 3.0,
    "priority_medium": 2.0,
    "priority_low": 1.0,
    "deadline_emphasis": 24.0
  },
  "entities": {
    "requester": {"ê¹€ì² ìˆ˜": 8.0, "ì´ì˜í¬": 4.0},
    "keyword": {"ê¸´ê¸‰": 3.0, "ë²„ê·¸": 2.5},
    "type": {"ë²„ê·¸ìˆ˜ì •": 3.0, "ê¸°ëŠ¥ê°œë°œ": 2.0},
    "time_range": {"ì˜¤ëŠ˜": 5.0, "ì´ë²ˆì£¼": 3.0}
  },
  "filters": {
    "created_after": "2025-10-20",
    "created_before": "2025-10-28",
    "status": ["pending", "in_progress"]
  }
}

**ê·œì¹™:**
- reset: trueë©´ ëª¨ë“  ê·œì¹™ ì´ˆê¸°í™” (ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ "ì´ˆê¸°í™”", "ë¦¬ì…‹", "reset" ë“±ì„ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ!)
- weights: ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ (0~10)
  - priority_high/medium/low: ìš°ì„ ìˆœìœ„ë³„ ê¸°ë³¸ ê°€ì¤‘ì¹˜
  - deadline_emphasis: ë°ë“œë¼ì¸ ê°•ì¡° (ì‹œê°„ ë‹¨ìœ„)
- entities: ì—”í‹°í‹°ë³„ ë³´ë„ˆìŠ¤ ì ìˆ˜ (0~10)
  - requester: ìš”ì²­ì ì´ë¦„ (ìµœìš°ì„ ì€ 8.0 ì´ìƒ!)
  - keyword: ì œëª©/ë‚´ìš©ì˜ í‚¤ì›Œë“œ
  - type: TODO ìœ í˜•
  - time_range: ì‹œê°„ ë²”ìœ„ ("ì˜¤ëŠ˜", "ì´ë²ˆì£¼", "ì´ë²ˆë‹¬" ë“±)
- filters: í•„í„° ì¡°ê±´ (ì„ íƒì‚¬í•­)
  - created_after/before: ìƒì„± ë‚ ì§œ ë²”ìœ„
  - status: ìƒíƒœ í•„í„°

**ì¤‘ìš”: resetì€ ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì´ˆê¸°í™”ë¥¼ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ trueë¡œ ì„¤ì •í•˜ì„¸ìš”!**
**ì¼ë°˜ì ì¸ ê·œì¹™ ì¶”ê°€ ìš”ì²­ì—ëŠ” resetì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”!**

**ì˜ˆì‹œ:**
ì…ë ¥: "ìœ ì¤€ì˜ ìµœìš°ì„ "
ì¶œë ¥: {"entities": {"requester": {"ìœ ì¤€ì˜": 9.0}}}

ì…ë ¥: "ìš”ì²­ìê°€ ì „í˜•ìš°ì¼ ê²½ìš° ìš°ì„ ìˆœìœ„ ë†’ê²Œ"
ì¶œë ¥: {"entities": {"requester": {"ì „í˜•ìš°": 5.0}}}

ì…ë ¥: "ë²„ê·¸ ë³´ê³ ì„œëŠ” ê¸´ê¸‰í•˜ê²Œ"
ì¶œë ¥: {"entities": {"keyword": {"ë²„ê·¸": 4.0, "ë³´ê³ ì„œ": 3.0}, "type": {"ë²„ê·¸": 4.0}}}

ì…ë ¥: "ì˜¤ëŠ˜ ìƒì„±ëœ TODO ìš°ì„ "
ì¶œë ¥: {"entities": {"time_range": {"ì˜¤ëŠ˜": 5.0}}, "filters": {"created_after": "2025-10-28"}}

ì…ë ¥: "ì´ë²ˆì£¼ ë°ë“œë¼ì¸ ê°•ì¡°"
ì¶œë ¥: {"weights": {"deadline_emphasis": 48.0}, "entities": {"time_range": {"ì´ë²ˆì£¼": 4.0}}}

ì…ë ¥: "ê¹€ì² ìˆ˜ ìš°ì„ , ë²„ê·¸ ê´€ë ¨ ì¤‘ìš”"
ì¶œë ¥: {"entities": {"requester": {"ê¹€ì² ìˆ˜": 5.0}, "keyword": {"ë²„ê·¸": 3.5}}}

ì…ë ¥: "ì´ˆê¸°í™”"
ì¶œë ¥: {"reset": true}
"""
        
        try:
            import requests
            
            headers = {"Authorization": f"Bearer {api_key}"}
            if provider == "openrouter":
                headers["HTTP-Referer"] = "https://github.com/your-repo"
            
            # AzureëŠ” JSON í˜•ì‹ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•´ì•¼ í•¨
            user_message = text
            if provider == "azure":
                user_message = f"{text}\n\në°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
            
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                "temperature": 0.3,
            }
            
            if provider in ("openai", "openrouter"):
                payload["response_format"] = {"type": "json_object"}
            
            logger.info("[Top3Service][LLM] provider=%s URL=%s text=%s", provider, url[:100], text[:200])
            logger.debug("[Top3Service][LLM] payload=%s", json.dumps(payload, ensure_ascii=False)[:500])
            
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            
            if response.status_code != 200:
                error_detail = response.text[:500]
                logger.error("[Top3Service][LLM] HTTP %d: %s", response.status_code, error_detail)
            
            response.raise_for_status()
            resp_json = response.json()
            
            logger.debug("[Top3Service][LLM] response=%s", json.dumps(resp_json, ensure_ascii=False)[:500])
            
            choices = resp_json.get("choices") or []
            if not choices:
                logger.error("[Top3Service][LLM] ì‘ë‹µì— choicesê°€ ì—†ìŒ: %s", json.dumps(resp_json, ensure_ascii=False)[:500])
                return None, "LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            
            content = choices[0].get("message", {}).get("content", "")
            logger.debug("[Top3Service][LLM] content=%s", content[:500])
            
            if not content or not content.strip():
                logger.error("[Top3Service][LLM] ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                return None, "LLM ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed = json.loads(content)
                logger.info("[Top3Service] LLM íŒŒì‹± ì„±ê³µ: %s", json.dumps(parsed, ensure_ascii=False)[:200])
                return parsed, "LLM íŒŒì‹± ì„±ê³µ"
            except json.JSONDecodeError as json_err:
                logger.error("[Top3Service][LLM] JSON íŒŒì‹± ì‹¤íŒ¨: %s, content=%s", json_err, content[:200])
                # JSONì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
                return None, f"JSON íŒŒì‹± ì‹¤íŒ¨: {json_err}"
            
        except requests.RequestException as exc:
            logger.warning("[Top3Service][LLM] request error: %s", exc)
            return None, f"LLM ìš”ì²­ ì‹¤íŒ¨: {exc}"
        except Exception as exc:
            logger.warning("[Top3Service][LLM] processing error: %s", exc)
            import traceback
            logger.debug(traceback.format_exc())
            return None, f"LLM ì²˜ë¦¬ ì˜¤ë¥˜: {exc}"
    
    def _heuristic_parse_rules(self, text: str) -> Tuple[Optional[Dict], str]:
        """íœ´ë¦¬ìŠ¤í‹± ë°©ì‹ìœ¼ë¡œ ìì—°ì–´ ê·œì¹™ íŒŒì‹±"""
        lower = text.lower()
        
        logger.debug(f"[Top3Service] íœ´ë¦¬ìŠ¤í‹± íŒŒì‹± ì‹œì‘: '{text}'")
        
        # ì´ˆê¸°í™” í‚¤ì›Œë“œ
        if any(word in lower for word in ["ì´ˆê¸°í™”", "ë¦¬ì…‹", "reset", "ê¸°ë³¸ê°’"]):
            logger.debug("[Top3Service] ì´ˆê¸°í™” í‚¤ì›Œë“œ ê°ì§€")
            return {"reset": True}, "íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì´ˆê¸°í™” ëª…ë ¹ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤."
        
        # ë³µí•© ì¡°ê±´ ê°ì§€ (LLMìœ¼ë¡œ ë„˜ê¹€)
        complex_keywords = ["ì´ê³ ", "ì´ë©°", "ê·¸ë¦¬ê³ ", "and", "ì°¸ì¡°", "cc", "bcc", "ì§ì ‘", "to"]
        if any(keyword in lower for keyword in complex_keywords):
            logger.debug(f"[Top3Service] ë³µí•© ì¡°ê±´ ê°ì§€ - LLM íŒŒì‹±ìœ¼ë¡œ ì „í™˜")
            return None, "ë³µí•© ì¡°ê±´ì´ ê°ì§€ë˜ì–´ LLM íŒŒì‹±ì´ í•„ìš”í•©ë‹ˆë‹¤"
        
        result = {"weights": {}, "entities": {"requester": {}, "type": {}}}
        
        # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ (í™•ì¥)
        priority_weights = {}
        high_priority_words = ["high", "ë†’", "ê¸´ê¸‰", "ì¤‘ìš”", "ìµœìš°ì„ ", "ê¸‰í•¨", "ì‹œê¸‰", "ì œì¼", "ë†’ê²Œ", "ë†’ì€"]
        
        if any(word in lower for word in high_priority_words):
            current_high = priority_weights.get("priority_high", TOP3_RULE_DEFAULT["priority_high"])
            priority_weights["priority_high"] = max(current_high, TOP3_RULE_DEFAULT["priority_high"] + 2.0)
            logger.debug(f"[Top3Service] ë†’ì€ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ê°ì§€: priority_high={priority_weights['priority_high']:.2f}")
        
        if any(word in lower for word in ["medium", "ì¤‘ê°„", "ë³´í†µ"]):
            priority_weights["priority_medium"] = max(
                priority_weights.get("priority_medium", TOP3_RULE_DEFAULT["priority_medium"]),
                TOP3_RULE_DEFAULT["priority_medium"] + 0.5
            )
            logger.debug(f"[Top3Service] ì¤‘ê°„ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ê°ì§€: priority_medium={priority_weights['priority_medium']:.2f}")
        
        if any(word in lower for word in ["low", "ë‚®", "ëœ ì¤‘ìš”", "ë‚®ê²Œ", "ìµœí•˜ìœ„"]):
            priority_weights["priority_low"] = max(0.2, TOP3_RULE_DEFAULT["priority_low"] - 2.0)
            logger.debug(f"[Top3Service] ë‚®ì€ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ê°ì§€: priority_low={priority_weights['priority_low']:.2f}")
        
        if priority_weights:
            result["weights"].update(priority_weights)
        
        # ìš”ì²­ì í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë‹¤ë¥¸ ë³´ë„ˆìŠ¤)
        # ìµœìš°ì„  í‚¤ì›Œë“œ ì²´í¬
        is_top_priority = any(word in lower for word in ["ìµœìš°ì„ ", "ë¬´ì¡°ê±´", "í•­ìƒ", "ë°˜ë“œì‹œ", "ê°€ì¥ ë¨¼ì €", "ìµœê³ ", "ì œì¼"])
        is_high_priority = any(word in lower for word in ["ìš°ì„ ", "ì¤‘ìš”", "ë¨¼ì €", "ë†’ê²Œ", "ë†’ì€"])
        
        # ë³´ë„ˆìŠ¤ ì ìˆ˜ ê²°ì • (ì¡°ì •)
        if is_top_priority:
            name_bonus = 8.0  # ìµœìš°ì„ : ë§¤ìš° ë†’ì€ ë³´ë„ˆìŠ¤ (7.0 â†’ 8.0)
        elif is_high_priority:
            name_bonus = 4.0  # ìš°ì„ : ë†’ì€ ë³´ë„ˆìŠ¤ (3.5 â†’ 4.0)
        else:
            name_bonus = 2.0  # ê¸°ë³¸ ë³´ë„ˆìŠ¤
        
        logger.debug(f"[Top3Service] ìš”ì²­ì ë³´ë„ˆìŠ¤ ì ìˆ˜: {name_bonus:.1f} (ìµœìš°ì„ ={is_top_priority}, ìš°ì„ ={is_high_priority})")
        
        # ìš”ì²­ì ì´ë¦„ ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)
        # íŒ¨í„´ 1: "XXXì´/ê°€ ìš”ì²­ì" í˜•íƒœ
        requester_pattern1 = r"([ê°€-í£]{2,6})(?:ì´|ê°€)\s*ìš”ì²­ì"
        # íŒ¨í„´ 2: "ìš”ì²­ìê°€ XXXì¼ ê²½ìš°" í˜•íƒœ (ê°€ì¥ ì¼ë°˜ì )
        requester_pattern2 = r"ìš”ì²­ì(?:ê°€|ëŠ”|ì´)?\s*([ê°€-í£]{2,6})(?:ì¼|ì´)?\s*(?:ê²½ìš°|ë•Œ|ë©´)"
        # íŒ¨í„´ 3: ì¼ë°˜ í•œê¸€ ì´ë¦„ + í˜¸ì¹­
        requester_pattern3 = r"([ê°€-í£]{2,6})\s*(?:ë‹˜|ì”¨|ì„ ìƒë‹˜|íŒ€ì¥|ë¶€ì¥)"
        # íŒ¨í„´ 4: "XXX ìš”ì²­" í˜•íƒœ
        requester_pattern4 = r"([ê°€-í£]{2,6})\s*ìš”ì²­"
        
        matches = set()
        matches.update(re.findall(requester_pattern1, text))
        matches.update(re.findall(requester_pattern2, text))
        matches.update(re.findall(requester_pattern3, text))
        matches.update(re.findall(requester_pattern4, text))
        
        logger.debug(f"[Top3Service] íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼: {matches}")
        
        # ë¶ˆìš©ì–´ ì œê±° (ì¼ë°˜ì ì¸ ë‹¨ì–´ ì œì™¸) - í™•ì¥
        stopwords = {
            "ìš”ì²­ì", "ìš°ì„ ìˆœìœ„", "ìµœìš°ì„ ", "ê²½ìš°", "ìš°ì„ ", "ì¤‘ìš”", "ë¨¼ì €", "ë†’ê²Œ", "ë†’ì€", "ì œì¼",
            "ìš”ì²­", "ìˆœìœ„", "ê·œì¹™", "ì„¤ì •", "ë³€ê²½", "ìˆ˜ì •", "ì¶”ê°€", "ì‚­ì œ", "ì´ˆê¸°í™”", "ë¦¬ì…‹"
        }
        matches = {name for name in matches if name not in stopwords and len(name) >= 2}
        
        # "XXXì¼", "XXXì´" í˜•íƒœ ì œê±° (ì˜ˆ: "ì •ì§€ì›ì¼" â†’ "ì •ì§€ì›", "ê¹€ì„¸ë¦°ì´" â†’ "ê¹€ì„¸ë¦°")
        cleaned_matches = set()
        for name in matches:
            cleaned_name = name
            # "ì¼" ì œê±°
            if name.endswith("ì¼") and len(name) > 2:
                cleaned_name = name[:-1]
                logger.debug(f"[Top3Service] ì´ë¦„ ì •ë¦¬ (ì¼): {name} â†’ {cleaned_name}")
            # "ì´" ì œê±° (ì¡°ì‚¬)
            elif name.endswith("ì´") and len(name) > 2:
                cleaned_name = name[:-1]
                logger.debug(f"[Top3Service] ì´ë¦„ ì •ë¦¬ (ì´): {name} â†’ {cleaned_name}")
            
            if len(cleaned_name) >= 2:
                cleaned_matches.add(cleaned_name)
        
        matches = cleaned_matches
        
        logger.debug(f"[Top3Service] ì¶”ì¶œëœ ì´ë¦„ í›„ë³´: {matches}")
        
        for name in matches:
            result["entities"]["requester"][name] = name_bonus
            logger.debug(f"[Top3Service] ìš”ì²­ì ê·œì¹™ ì¶”ê°€: {name} â†’ ë³´ë„ˆìŠ¤ {name_bonus:.1f}")
            
            # í•œêµ­ì–´ ì´ë¦„ ì •ê·œí™”
            from .top3_korean_utils import normalize_korean_name
            normalized = normalize_korean_name(name)
            if normalized != name:
                result["entities"]["requester"][normalized] = name_bonus
                logger.debug(f"[Top3Service] ì •ê·œí™”ëœ ì´ë¦„ ì¶”ê°€: {normalized} â†’ ë³´ë„ˆìŠ¤ {name_bonus:.1f}")
        
        # ìœ í˜•(type) í‚¤ì›Œë“œ ì¶”ì¶œ
        # íŒ¨í„´: "XXX ìœ í˜•", "XXX íƒ€ì…", "XXX ê´€ë ¨", "XXX TODO"
        type_pattern1 = r"([ê°€-í£a-zA-Z]{2,10})\s*(?:ìœ í˜•|íƒ€ì…|ê´€ë ¨|TODO)"
        # íŒ¨í„´: "ìœ í˜•ì´ XXX", "íƒ€ì…ì´ XXX"
        type_pattern2 = r"(?:ìœ í˜•|íƒ€ì…)(?:ì´|ê°€)?\s*([ê°€-í£a-zA-Z]{2,10})"
        
        type_matches = set()
        type_matches.update(re.findall(type_pattern1, text))
        type_matches.update(re.findall(type_pattern2, text))
        
        # ë¶ˆìš©ì–´ ì œê±°
        type_stopwords = {"ìœ í˜•", "íƒ€ì…", "ê´€ë ¨", "TODO", "ê²½ìš°", "ìš°ì„ ", "ì¤‘ìš”", "ë¨¼ì €", "ë†’ê²Œ"}
        type_matches = {t for t in type_matches if t not in type_stopwords and len(t) >= 2}
        
        logger.debug(f"[Top3Service] ì¶”ì¶œëœ ìœ í˜• í›„ë³´: {type_matches}")
        
        for type_name in type_matches:
            result["entities"]["type"][type_name] = name_bonus
            logger.debug(f"[Top3Service] ìœ í˜• ê·œì¹™ ì¶”ê°€: {type_name} â†’ ë³´ë„ˆìŠ¤ {name_bonus:.1f}")
        
        # ê²°ê³¼ í™•ì¸
        if not result["weights"] and not result["entities"]["requester"] and not result["entities"]["type"]:
            return None, "ê·œì¹™ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        
        note = "íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ê·œì¹™ì„ í•´ì„í–ˆìŠµë‹ˆë‹¤."
        if result["entities"]["requester"]:
            note += f" (ìš”ì²­ì: {', '.join(result['entities']['requester'].keys())})"
        if result["entities"]["type"]:
            note += f" (ìœ í˜•: {', '.join(result['entities']['type'].keys())})"
        
        return result, note
    
    def _save_rules(self) -> None:
        """ê·œì¹™ì„ íŒŒì¼ì— ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            
            data = {
                "weights": self.get_rules(),
                "entities": self.get_entity_rules(),
                "instruction": self._last_instruction
            }
            
            with open(self.config_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info("[Top3Service] rules saved to %s", self.config_path)
        except Exception as exc:
            logger.error("[Top3Service] failed to save rules: %s", exc)
    
    def _load_rules(self) -> None:
        """íŒŒì¼ì—ì„œ ê·œì¹™ ë¡œë“œ"""
        try:
            if not os.path.exists(self.config_path):
                return
            
            with open(self.config_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            weights = data.get("weights")
            entities = data.get("entities")
            instruction = data.get("instruction")
            
            if isinstance(weights, dict) and weights:
                self.set_rules(weights)
            
            if isinstance(entities, dict):
                self.update_entity_rules(entities, reset=True)
            
            if isinstance(instruction, str):
                self._last_instruction = instruction
            
            logger.info("[Top3Service] rules loaded from %s", self.config_path)
        except Exception as exc:
            logger.warning("[Top3Service] failed to load rules: %s", exc)

    def get_last_reasoning(self) -> str:
        """ë§ˆì§€ë§‰ Top3 ì„ ì • ì´ìœ  ê°€ì ¸ì˜¤ê¸° (í•œêµ­ì–´)
        
        Returns:
            ì„ ì • ì´ìœ  ë¬¸ìì—´ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
        """
        return self._last_reasoning
    
    def _deduplicate_by_source(self, todos: List[Dict]) -> List[Dict]:
        """ê°™ì€ source_messageë¥¼ ê°€ì§„ TODO ì¤‘ë³µ ì œê±°
        
        ê°™ì€ ë©”ì‹œì§€ì—ì„œ ì—¬ëŸ¬ ìœ í˜•ì˜ TODOê°€ ìƒì„±ëœ ê²½ìš°,
        ìš°ì„ ìˆœìœ„ê°€ ê°€ì¥ ë†’ì€ ìœ í˜• 1ê°œë§Œ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            todos: TODO ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì¤‘ë³µ ì œê±°ëœ TODO ë¦¬ìŠ¤íŠ¸
        """
        # ìœ í˜• ìš°ì„ ìˆœìœ„ (TodoDeduplicationServiceì™€ ë™ì¼)
        TYPE_PRIORITY = {
            "deadline": 6,
            "meeting": 5,
            "task": 4,
            "review": 3,
            "documentation": 2,
            "issue": 1,
        }
        
        # source_messageë³„ë¡œ ê·¸ë£¹í™”
        source_groups = {}
        for todo in todos:
            source_msg = todo.get("source_message")
            
            if not source_msg:
                # source_messageê°€ ì—†ìœ¼ë©´ ê°œë³„ TODOë¡œ ì²˜ë¦¬
                unique_key = f"no_source_{todo.get('id', '')}"
                source_groups[unique_key] = [todo]
            else:
                # source_messageê°€ dictì¸ ê²½ìš° IDë¥¼ í‚¤ë¡œ ì‚¬ìš©
                if isinstance(source_msg, dict):
                    source_key = source_msg.get("id") or source_msg.get("message_id") or str(source_msg)
                else:
                    source_key = str(source_msg)
                
                if source_key not in source_groups:
                    source_groups[source_key] = []
                source_groups[source_key].append(todo)
        
        # ê° ê·¸ë£¹ì—ì„œ ìµœì„  TODO ì„ íƒ
        deduplicated = []
        removed_count = 0
        
        for source_msg, group in source_groups.items():
            if len(group) == 1:
                # ì¤‘ë³µ ì—†ìŒ
                deduplicated.append(group[0])
            else:
                # ì¤‘ë³µ ìˆìŒ - ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
                sorted_group = sorted(
                    group,
                    key=lambda t: (
                        TYPE_PRIORITY.get(t.get("type", "task"), 0),
                        t.get("created_at", "")
                    ),
                    reverse=True
                )
                
                best_todo = sorted_group[0]
                deduplicated.append(best_todo)
                removed_count += len(group) - 1
                
                logger.debug(
                    f"[Top3Service] ì¤‘ë³µ ì œê±°: source={source_msg}, "
                    f"{len(group)}ê°œ ì¤‘ {best_todo.get('type')} ì„ íƒ"
                )
        
        if removed_count > 0:
            logger.info(
                f"[Top3Service] ğŸ—‘ï¸ Top3 í›„ë³´ ì¤‘ë³µ ì œê±°: "
                f"{len(todos)}ê°œ â†’ {len(deduplicated)}ê°œ ({removed_count}ê°œ ì œê±°)"
            )
        
        return deduplicated
