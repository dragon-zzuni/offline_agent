# -*- coding: utf-8 -*-
"""
Top3 TODO ì„ ì • ë° ê·œì¹™ ê´€ë¦¬ ì„œë¹„ìŠ¤

TODO í•­ëª©ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ê³„ì‚°í•˜ê³  Top3ë¥¼ ìë™ìœ¼ë¡œ ì„ ì •í•©ë‹ˆë‹¤.
ìì—°ì–´ ê·œì¹™ í•´ì„ ë° LLM ê¸°ë°˜ ê·œì¹™ íŒŒì‹±ì„ ì§€ì›í•©ë‹ˆë‹¤.
"""
import os
import json
import logging
import re
from copy import deepcopy
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Tuple, Set

logger = logging.getLogger(__name__)

# Top-3 ê·œì¹™ ê¸°ë³¸ê°’
TOP3_RULE_DEFAULT = {
    "priority_high": 3.0,
    "priority_medium": 2.0,
    "priority_low": 1.0,
    "deadline_emphasis": 24.0,
    "deadline_base": 1.0,
    "evidence_per_item": 0.1,
    "evidence_max_bonus": 0.5,
    "recipient_type_cc_penalty": 0.7,
}

# ì—”í‹°í‹° ê·œì¹™ ê¸°ë³¸ê°’
ENTITY_RULES_DEFAULT = {
    "requester": {},
    "type": {},
}


class Top3Service:
    """Top3 TODO ì„ ì • ë° ê·œì¹™ ê´€ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config_path: Optional[str] = None, people_data: Optional[List[Dict]] = None, vdos_connector=None):
        """
        Args:
            config_path: ê·œì¹™ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            people_data: ì‚¬ëŒ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ì´ë©”ì¼â†’ì´ë¦„ ë§¤í•‘ìš©)
            vdos_connector: VDOSConnector ì¸ìŠ¤í„´ìŠ¤ (ì‹¤ì‹œê°„ people ë°ì´í„°ìš©)
        """
        # VDOS DB ìœ„ì¹˜ì— ì„¤ì • íŒŒì¼ ì €ì¥
        if config_path is None:
            if vdos_connector and vdos_connector.is_available:
                # vdos.dbì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ì €ì¥
                vdos_dir = os.path.dirname(vdos_connector.vdos_db_path)
                config_path = os.path.join(vdos_dir, "top3_config.json")
            else:
                # í´ë°±: ê¸°ë³¸ ê²½ë¡œ
                config_path = os.path.join("data", "top3_config.json")
        
        self.config_path = config_path
        self._rules = deepcopy(TOP3_RULE_DEFAULT)
        self._entity_rules = deepcopy(ENTITY_RULES_DEFAULT)
        self._last_instruction = ""
        self._vdos_connector = vdos_connector
        
        # ì´ë©”ì¼ â†’ ì´ë¦„ ë§¤í•‘ êµ¬ì¶•
        self._email_to_name = {}
        
        # people_data ë¡œë“œ ìš°ì„ ìˆœìœ„: 1) íŒŒë¼ë¯¸í„°, 2) VDOS, 3) JSON íŒŒì¼
        if people_data is None:
            if vdos_connector and vdos_connector.is_available:
                people_data = vdos_connector.get_people()
                logger.info(f"[Top3Service] VDOSì—ì„œ people ë°ì´í„° ë¡œë“œ: {len(people_data)}ëª…")
            else:
                people_data = self._load_people_data()
        
        if people_data:
            for person in people_data:
                email = person.get("email_address", "")
                name = person.get("name", "")
                if email and name:
                    self._email_to_name[email.lower()] = name
                    logger.debug(f"[Top3Service] ì´ë©”ì¼ ë§¤í•‘: {email} â†’ {name}")
        
        logger.info(f"[Top3Service] ì´ˆê¸°í™” ì™„ë£Œ: {len(self._email_to_name)}ê°œ ì´ë©”ì¼ ë§¤í•‘")
        
        # ì €ì¥ëœ ê·œì¹™ ë¡œë“œ
        self._load_rules()
    
    def _load_people_data(self) -> List[Dict]:
        """people ë°ì´í„° ìë™ ë¡œë“œ"""
        try:
            # people íŒŒì¼ ì°¾ê¸° (ì ˆëŒ€ ê²½ë¡œ ë° ìƒëŒ€ ê²½ë¡œ ëª¨ë‘ ì‹œë„)
            data_dir = os.path.dirname(self.config_path)
            
            # ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹ˆë©´ í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
            if not os.path.isabs(data_dir):
                data_dir = os.path.abspath(data_dir)
            
            logger.debug(f"[Top3Service] people ë°ì´í„° ê²€ìƒ‰ ê²½ë¡œ: {data_dir}")
            
            if not os.path.exists(data_dir):
                logger.warning(f"[Top3Service] ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_dir}")
                return []
            
            people_files = [f for f in os.listdir(data_dir) if f.startswith("people_") and f.endswith(".json")]
            
            if not people_files:
                logger.warning(f"[Top3Service] people ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ê²½ë¡œ: {data_dir})")
                return []
            
            # ê°€ì¥ ìµœì‹  íŒŒì¼ ì‚¬ìš©
            people_file = sorted(people_files)[-1]
            people_path = os.path.join(data_dir, people_file)
            
            logger.debug(f"[Top3Service] people íŒŒì¼ ë¡œë“œ ì‹œë„: {people_path}")
            
            with open(people_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                people_list = data.get("people", [])
                logger.info(f"[Top3Service] people ë°ì´í„° ë¡œë“œ ì„±ê³µ: {people_file} ({len(people_list)}ëª…)")
                return people_list
        except Exception as e:
            logger.error(f"[Top3Service] people ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return []
    
    def get_rules(self) -> Dict[str, float]:
        """í˜„ì¬ ê·œì¹™ ë°˜í™˜"""
        return dict(self._rules)
    
    def get_entity_rules(self) -> Dict[str, Dict[str, float]]:
        """í˜„ì¬ ì—”í‹°í‹° ê·œì¹™ ë°˜í™˜"""
        return {k: dict(v) for k, v in self._entity_rules.items()}
    
    def get_last_instruction(self) -> str:
        """ë§ˆì§€ë§‰ ìì—°ì–´ ì§€ì‹œì‚¬í•­ ë°˜í™˜"""
        return self._last_instruction
    
    def set_rules(self, new_rules: Dict[str, float]) -> None:
        """ê·œì¹™ ì„¤ì •"""
        for key, default in TOP3_RULE_DEFAULT.items():
            value = new_rules.get(key)
            if value is None:
                continue
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if not isinstance(value, (int, float)):
                continue
            
            # ë²”ìœ„ ì œí•œ
            if key.startswith("priority_"):
                if value < 0:
                    value = 0.0
                if value > 10:
                    value = 10.0
            elif key == "deadline_emphasis":
                if value < 0:
                    value = 0.0
                if value > 100:
                    value = 100.0
            elif key == "deadline_base":
                if value < 0:
                    value = 0.0
                if value > 10:
                    value = 10.0
            elif key == "evidence_per_item":
                if value < 0:
                    value = 0.0
                if value > 1:
                    value = 1.0
            elif key == "evidence_max_bonus":
                if value < 0:
                    value = 0.0
            elif key == "recipient_type_cc_penalty":
                if value < 0:
                    value = 0.0
                if value > 1:
                    value = 1.0
            
            self._rules[key] = value
    
    def update_entity_rules(self, new_rules: Optional[Dict[str, Dict[str, float]]], reset: bool = False) -> None:
        """ì—”í‹°í‹° ê·œì¹™ ì—…ë°ì´íŠ¸"""
        if reset:
            for cat in ENTITY_RULES_DEFAULT:
                self._entity_rules[cat].clear()
        
        if not new_rules:
            return
        
        for category, mapping in new_rules.items():
            if category not in self._entity_rules:
                continue
            
            dest = self._entity_rules[category]
            for key, value in (mapping or {}).items():
                if value is None:
                    dest.pop(key, None)
                    continue
                
                if not isinstance(value, (int, float)):
                    continue
                
                # ë²”ìœ„ ì œí•œ
                if value < -10:
                    value = -10.0
                if value > 10:
                    value = 10.0
                
                dest[key] = value
                
                # í•œêµ­ì–´ ì´ë¦„ ë³€í˜• ì²˜ë¦¬
                if category == "requester":
                    from .top3_korean_utils import normalize_korean_name, generate_korean_name_variations
                    
                    normalized = normalize_korean_name(key)
                    if normalized != key:
                        dest[normalized] = max(dest.get(normalized, 0.0), value)
                    
                    variations = generate_korean_name_variations(key)
                    for variation in variations:
                        if variation not in dest:
                            dest[variation] = value
                        else:
                            dest[variation] = max(dest.get(variation, 0.0), value)
    
    def calculate_score(self, todo: Dict) -> float:
        """TODO í•­ëª©ì˜ ì ìˆ˜ ê³„ì‚°"""
        # ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜
        priority = (todo.get("priority") or "low").lower()
        w_priority = self._rules.get(f"priority_{priority}", self._rules["priority_low"])
        
        # ë°ë“œë¼ì¸ ì„ë°• ê°€ì¤‘ì¹˜
        now = datetime.now(timezone.utc)
        deadline = todo.get("deadline_ts") or todo.get("deadline")
        
        if deadline:
            try:
                dl = datetime.fromisoformat(deadline.replace("Z", "+00:00"))
            except Exception:
                try:
                    dl = datetime.fromisoformat(deadline)
                except Exception:
                    dl = None
        else:
            dl = None
        
        if dl:
            if dl.tzinfo is None:
                dl = dl.replace(tzinfo=timezone.utc)
            hours_left = max(0.0, (dl - now).total_seconds() / 3600.0)
            emphasis = self._rules.get("deadline_emphasis", 24.0)
            base = self._rules.get("deadline_base", 1.0)
            w_deadline = base + (emphasis / (emphasis + hours_left))
        else:
            w_deadline = 1.0
        
        # ê·¼ê±° ê°€ì¤‘ì¹˜
        evidence = todo.get("evidence")
        if not isinstance(evidence, list):
            try:
                evidence = json.loads(evidence or "[]")
            except Exception:
                evidence = []
        
        per_item = self._rules.get("evidence_per_item", 0.1)
        max_bonus = self._rules.get("evidence_max_bonus", 0.5)
        w_evidence = 1.0 + min(max_bonus, per_item * len(evidence))
        
        # ì—”í‹°í‹° ê·œì¹™ ì ìš© (ìì—°ì–´ ê·œì¹™)
        rule_multiplier = 1.0
        priority_bonus = 0.0
        
        # ìš”ì²­ì ë³´ë„ˆìŠ¤ (ë” ê°•ë ¥í•˜ê²Œ ì ìš©)
        requester = (todo.get("requester") or "").lower()
        if requester:
            for match, bonus in self._entity_rules.get("requester", {}).items():
                if match and match in requester:
                    priority_bonus += bonus
                    rule_multiplier += bonus * 0.25
            
            # ì„í˜¸ê·œ íŠ¹ë³„ ë§¤ì¹­ (ì´ë©”ì¼ ì£¼ì†Œ í¬í•¨)
            hongyu_patterns = ["ì„í˜¸ê·œ", "hongyu", "imhokyu", "lim", "ho", "gyu"]
            if any(pattern in requester for pattern in hongyu_patterns):
                for pattern in hongyu_patterns:
                    if pattern in self._entity_rules.get("requester", {}):
                        bonus = self._entity_rules["requester"][pattern]
                        priority_bonus += bonus
                        rule_multiplier += bonus * 0.25
                        break
        
        # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤ (ì œëª©, ì„¤ëª…, íƒ€ì…ì—ì„œ ê²€ìƒ‰)
        text_fields = " ".join([
            todo.get("title", ""),
            todo.get("description", ""),
            todo.get("type", ""),
        ]).lower()
        
        for match, bonus in self._entity_rules.get("keyword", {}).items():
            if match and match in text_fields:
                priority_bonus += bonus * 0.5
                rule_multiplier += bonus * 0.25
        
        # íƒ€ì… ë³´ë„ˆìŠ¤
        todo_type = (todo.get("type") or "").lower()
        for match, bonus in self._entity_rules.get("type", {}).items():
            if match and match in todo_type:
                priority_bonus += bonus * 0.5
                rule_multiplier += bonus * 0.25
        
        # rule_multiplier ë²”ìœ„ ì œí•œ
        rule_multiplier = max(0.5, min(rule_multiplier, 6.0))
        
        # priority_term ê³„ì‚° (ì—”í‹°í‹° ë³´ë„ˆìŠ¤ ì ìš©)
        if priority_bonus > 0:
            priority_floor = max(self._rules.get("priority_high", 3.0) + priority_bonus, 3.5)
        else:
            priority_floor = 0.0
        
        priority_term = max(0.1, w_priority + priority_bonus, priority_floor)
        
        # ìˆ˜ì‹  íƒ€ì… í˜ë„í‹° (CC/BCC)
        recipient_type = (todo.get("recipient_type") or "to").lower()
        cc_penalty = 1.0
        if recipient_type == "cc":
            cc_penalty = self._rules.get("recipient_type_cc_penalty", 0.7)
        elif recipient_type == "bcc":
            cc_penalty = self._rules.get("recipient_type_cc_penalty", 0.7) * 0.9
        
        # ìµœì¢… ì ìˆ˜ (ì—”í‹°í‹° ê·œì¹™ì´ ê°•ë ¥í•˜ê²Œ ì ìš©ë¨)
        score = (priority_term * rule_multiplier) * w_deadline * w_evidence * cc_penalty
        return score
    
    def _normalize_name(self, name: str) -> str:
        """ì´ë¦„ ì •ê·œí™” (ê³µë°±, ëŒ€ì†Œë¬¸ì, íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì´ë©”ì¼ ì£¼ì†Œ ì²˜ë¦¬)
        
        Args:
            name: ì •ê·œí™”í•  ì´ë¦„
            
        Returns:
            ì •ê·œí™”ëœ ì´ë¦„ (ì†Œë¬¸ì, ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        """
        if not name:
            return ""
        
        # ì†Œë¬¸ì ë³€í™˜
        normalized = name.lower().strip()
        
        # ì´ë©”ì¼ ì£¼ì†Œì—ì„œ ì´ë¦„ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if "@" in normalized:
            normalized = normalized.split("@")[0]
        
        # ê³µë°± ì œê±°
        normalized = normalized.replace(" ", "").replace("\t", "")
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ìœ ì§€)
        normalized = re.sub(r"[^a-z0-9ê°€-í£]", "", normalized)
        
        return normalized
    
    def _match_requester(self, requester: str, rules: Dict[str, float]) -> bool:
        """ìš”ì²­ìê°€ ê·œì¹™ì— ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸ (ì™„ì „ ì¼ì¹˜ ë° ë¶€ë¶„ ì¼ì¹˜, ì´ë©”ì¼â†’ì´ë¦„ ë³€í™˜)
        
        Args:
            requester: TODOì˜ ìš”ì²­ì (ì´ë©”ì¼ ë˜ëŠ” ì´ë¦„)
            rules: ìš”ì²­ì ê·œì¹™ ë”•ì…”ë„ˆë¦¬ {ì´ë¦„: ë³´ë„ˆìŠ¤}
            
        Returns:
            ë§¤ì¹­ ì—¬ë¶€
        """
        if not requester or not rules:
            return False
        
        # ì´ë©”ì¼ ì£¼ì†Œì¸ ê²½ìš° ì´ë¦„ìœ¼ë¡œ ë³€í™˜
        requester_name = requester
        if "@" in requester:
            requester_name = self._email_to_name.get(requester.lower(), requester)
            logger.debug(f"[Top3Service] ì´ë©”ì¼â†’ì´ë¦„ ë³€í™˜: {requester} â†’ {requester_name}")
        
        # ì •ê·œí™”
        normalized_requester = self._normalize_name(requester_name)
        
        for rule_name in rules.keys():
            normalized_rule = self._normalize_name(rule_name)
            
            # ì™„ì „ ì¼ì¹˜
            if normalized_requester == normalized_rule:
                logger.debug(f"[Top3Service] âœ“ ì™„ì „ ì¼ì¹˜: requester={requester_name}, rule={rule_name}")
                return True
            
            # ë¶€ë¶„ ì¼ì¹˜ (í•œêµ­ì–´ ì´ë¦„ì€ ì—„ê²©í•˜ê²Œ)
            # ê·œì¹™ì´ ìš”ì²­ìì— í¬í•¨ë˜ëŠ” ê²½ìš°ë§Œ í—ˆìš© (ì—­ë°©í–¥ ì œì™¸)
            # ì˜ˆ: ê·œì¹™="ê¹€ì² ìˆ˜", ìš”ì²­ì="ê¹€ì² ìˆ˜ë‹˜" â†’ OK
            # ì˜ˆ: ê·œì¹™="ê¹€ì² ìˆ˜ë‹˜", ìš”ì²­ì="ê¹€ì² ìˆ˜" â†’ NO (ë„ˆë¬´ ëŠìŠ¨í•¨)
            if normalized_rule and len(normalized_rule) >= 2:
                if normalized_rule in normalized_requester and len(normalized_requester) - len(normalized_rule) <= 2:
                    # ê¸¸ì´ ì°¨ì´ê°€ 2 ì´í•˜ì¼ ë•Œë§Œ ë¶€ë¶„ ì¼ì¹˜ í—ˆìš© (í˜¸ì¹­ ì •ë„ë§Œ)
                    logger.debug(f"[Top3Service] âœ“ ë¶€ë¶„ ì¼ì¹˜ (ê·œì¹™â†’ìš”ì²­ì): requester={requester_name}, rule={rule_name}")
                    return True
        
        logger.debug(f"[Top3Service] âœ— ë§¤ì¹­ ì‹¤íŒ¨: requester={requester_name} (ì›ë³¸={requester})")
        return False
    
    def _filter_by_rules(self, candidates: List[Dict]) -> List[Dict]:
        """ê·œì¹™ì— ë§¤ì¹­ë˜ëŠ” TODO í•„í„°ë§
        
        Args:
            candidates: í›„ë³´ TODO ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê·œì¹™ì— ë§¤ì¹­ë˜ëŠ” TODO ë¦¬ìŠ¤íŠ¸
        """
        requester_rules = self._entity_rules.get("requester", {})
        
        if not requester_rules:
            logger.debug("[Top3Service] ìš”ì²­ì ê·œì¹™ ì—†ìŒ, í•„í„°ë§ ìŠ¤í‚µ")
            return []
        
        logger.info(f"[Top3Service] ê·œì¹™ ì ìš© ì‹œì‘: {len(requester_rules)}ê°œ ìš”ì²­ì ê·œì¹™, {len(candidates)}ê°œ í›„ë³´ TODO")
        logger.debug(f"[Top3Service] ê·œì¹™ ëª©ë¡: {list(requester_rules.keys())}")
        
        matched = []
        unmatched_requesters = set()
        
        for item in candidates:
            requester = item.get("requester", "")
            if not requester:
                continue
            
            # ê·œì¹™ê³¼ ë§¤ì¹­ í™•ì¸
            if self._match_requester(requester, requester_rules):
                matched.append(item)
                logger.debug(f"[Top3Service] ê·œì¹™ ë§¤ì¹­ ì„±ê³µ: TODO={item.get('title', '')[:30]}, ìš”ì²­ì={requester}")
            else:
                unmatched_requesters.add(requester)
        
        if unmatched_requesters:
            logger.debug(f"[Top3Service] ê·œì¹™ ë¯¸ë§¤ì¹­ ìš”ì²­ì: {list(unmatched_requesters)[:5]}")
        
        logger.info(f"[Top3Service] ê·œì¹™ ë§¤ì¹­ ì™„ë£Œ: {len(matched)}ê°œ TODO ë§¤ì¹­, {len(unmatched_requesters)}ê°œ ìš”ì²­ì ë¯¸ë§¤ì¹­")
        return matched
    
    def pick_top3(self, items: List[Dict]) -> Set[str]:
        """Top3 TODO ì„ ì • (ê·œì¹™ ê°•ì œ ì ìš©)
        
        ìì—°ì–´ ê·œì¹™ì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ê·œì¹™ì— ë§ëŠ” TODOë§Œ Top3ì— í‘œì‹œ
        ê·œì¹™ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ì ìˆ˜ ê¸°ë°˜ ì„ ì •
        """
        # 1. statusê°€ doneì´ ì•„ë‹Œ ê²ƒë§Œ í›„ë³´
        candidates = [x for x in items if (x.get("status") or "pending") not in ("done",)]
        
        # 2. ìì—°ì–´ ê·œì¹™ í™•ì¸
        has_natural_rules = bool(self._entity_rules.get("requester") or 
                                 self._entity_rules.get("keyword") or 
                                 self._entity_rules.get("type"))
        
        if has_natural_rules:
            # ìì—°ì–´ ê·œì¹™ì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ê·œì¹™ ë§¤ì¹­ TODOë§Œ ì„ ì •
            logger.info(f"[Top3Service] ğŸ”’ ê°•ì œ ëª¨ë“œ: ìì—°ì–´ ê·œì¹™ì— ë§ëŠ” TODOë§Œ Top3 ì„ ì •")
            
            # ê·œì¹™ ë§¤ì¹­ TODO í•„í„°ë§
            rule_matched = self._filter_by_rules(candidates)
            
            if not rule_matched:
                logger.warning(f"[Top3Service] âš ï¸ ê·œì¹™ì— ë§ëŠ” TODOê°€ ì—†ìŒ (ì „ì²´ {len(candidates)}ê°œ ì¤‘)")
                return set()
            
            # ê·œì¹™ ë§¤ì¹­ TODOë¥¼ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
            for item in rule_matched:
                item["_top3_score"] = self.calculate_score(item)
            
            def _created_iso(x):
                return x.get("created_at") or datetime.now().isoformat()
            
            rule_matched.sort(key=lambda x: (x["_top3_score"], _created_iso(x)), reverse=True)
            
            # ê·œì¹™ ë§¤ì¹­ TODOì—ì„œ ìµœëŒ€ 3ê°œ ì„ ì • (3ê°œ ë¯¸ë§Œì´ì–´ë„ ì±„ìš°ì§€ ì•ŠìŒ)
            top3_ids = set()
            for item in rule_matched[:3]:
                if item.get("id"):
                    top3_ids.add(item["id"])
            
            logger.info(f"[Top3Service] âœ… ê°•ì œ ëª¨ë“œ ì™„ë£Œ: ê·œì¹™ ë§¤ì¹­ {len(rule_matched)}ê°œ ì¤‘ {len(top3_ids)}ê°œ ì„ ì •")
            return top3_ids
        
        else:
            # ìì—°ì–´ ê·œì¹™ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ì ìˆ˜ ê¸°ë°˜ ì„ ì •
            logger.info(f"[Top3Service] ğŸ“Š ì¼ë°˜ ëª¨ë“œ: ì ìˆ˜ ê¸°ë°˜ Top3 ì„ ì •")
            
            # ëª¨ë“  í›„ë³´ì˜ ì ìˆ˜ ê³„ì‚°
            for item in candidates:
                item["_top3_score"] = self.calculate_score(item)
            
            def _created_iso(x):
                return x.get("created_at") or datetime.now().isoformat()
            
            candidates.sort(key=lambda x: (x["_top3_score"], _created_iso(x)), reverse=True)
            
            # ìƒìœ„ 3ê°œ ì„ ì •
            top3_ids = set()
            for item in candidates[:3]:
                if item.get("id"):
                    top3_ids.add(item["id"])
            
            logger.info(f"[Top3Service] âœ… ì¼ë°˜ ëª¨ë“œ ì™„ë£Œ: {len(candidates)}ê°œ ì¤‘ {len(top3_ids)}ê°œ ì„ ì •")
            return top3_ids
    
    def describe_rules(self) -> str:
        """í˜„ì¬ ê·œì¹™ì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…"""
        rules = self.get_rules()
        entity_rules = self.get_entity_rules()
        
        # ìì—°ì–´ ê·œì¹™ í™•ì¸
        has_natural_rules = bool(entity_rules.get("requester") or 
                                 entity_rules.get("keyword") or 
                                 entity_rules.get("type"))
        
        parts = []
        
        if has_natural_rules:
            parts.append("ğŸ”’ ê°•ì œ ëª¨ë“œ: ìì—°ì–´ ê·œì¹™ì— ë§ëŠ” TODOë§Œ Top3 í‘œì‹œ")
            
            if entity_rules.get("requester"):
                requester_list = ", ".join(list(entity_rules["requester"].keys())[:5])
                if len(entity_rules["requester"]) > 5:
                    requester_list += f" ì™¸ {len(entity_rules['requester']) - 5}ëª…"
                parts.append(f"  â€¢ ìš”ì²­ì: {requester_list}")
            
            if entity_rules.get("keyword"):
                keyword_list = ", ".join(list(entity_rules["keyword"].keys())[:5])
                if len(entity_rules["keyword"]) > 5:
                    keyword_list += f" ì™¸ {len(entity_rules['keyword']) - 5}ê°œ"
                parts.append(f"  â€¢ í‚¤ì›Œë“œ: {keyword_list}")
            
            if entity_rules.get("type"):
                type_list = ", ".join(list(entity_rules["type"].keys())[:5])
                if len(entity_rules["type"]) > 5:
                    type_list += f" ì™¸ {len(entity_rules['type']) - 5}ê°œ"
                parts.append(f"  â€¢ íƒ€ì…: {type_list}")
        else:
            parts.append("ğŸ“Š ì¼ë°˜ ëª¨ë“œ: ì ìˆ˜ ê¸°ë°˜ Top3 ì„ ì •")
        
        parts.extend([
            f"ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ H/M/L: {rules.get('priority_high',0):.2f}/{rules.get('priority_medium',0):.2f}/{rules.get('priority_low',0):.2f}",
            f"ë°ë“œë¼ì¸ ê°•ì¡°: {rules.get('deadline_emphasis',0):.1f}ì‹œê°„",
            f"ê·¼ê±°ë‹¹ ê°€ì¤‘ì¹˜: {rules.get('evidence_per_item',0):.2f} (ìµœëŒ€ {rules.get('evidence_max_bonus',0):.2f})",
            f"CC/BCC í˜ë„í‹°: {rules.get('recipient_type_cc_penalty',0):.2f}",
        ])
        
        return "\n".join(parts)
    
    def apply_natural_language_rules(self, text: str, reset: bool = False) -> Tuple[str, str]:
        """
        ìì—°ì–´ ì§€ì‹œì‚¬í•­ì„ ê·œì¹™ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ìì—°ì–´ ì§€ì‹œì‚¬í•­
            reset: ê·œì¹™ ì´ˆê¸°í™” ì—¬ë¶€
            
        Returns:
            Tuple[str, str]: (ê²°ê³¼ ë©”ì‹œì§€, í˜„ì¬ ê·œì¹™ ì„¤ëª…)
        """
        cleaned_text = text.strip()
        
        if reset or not cleaned_text:
            self._last_instruction = "" if reset else cleaned_text
            self.set_rules(TOP3_RULE_DEFAULT)
            self.update_entity_rules({}, reset=True)
            self._save_rules()
            logger.info("[Top3Service] rules reset by user input")
            return "ê·œì¹™ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.", self.describe_rules()
        
        # íœ´ë¦¬ìŠ¤í‹± íŒŒì‹± ë¨¼ì € ì‹œë„ (ë” ì•ˆì •ì )
        logger.info(f"[Top3Service] ìì—°ì–´ ê·œì¹™ íŒŒì‹± ì‹œì‘: '{cleaned_text[:50]}...'")
        parsed, heuristic_note = self._heuristic_parse_rules(cleaned_text)
        
        if parsed:
            logger.info(f"[Top3Service] íœ´ë¦¬ìŠ¤í‹± íŒŒì‹± ì„±ê³µ: {heuristic_note}")
            llm_message = heuristic_note
        else:
            # íœ´ë¦¬ìŠ¤í‹± ì‹¤íŒ¨ ì‹œ LLM íŒŒì‹±
            logger.warning(f"[Top3Service] íœ´ë¦¬ìŠ¤í‹± íŒŒì‹± ì‹¤íŒ¨, LLM íŒŒì‹±ìœ¼ë¡œ ì „í™˜")
            parsed, llm_message = self._try_llm_parse_rules(cleaned_text)
            
            if parsed:
                logger.info(f"[Top3Service] LLM íŒŒì‹± ì„±ê³µ: {llm_message}")
            else:
                logger.warning(f"[Top3Service] LLM íŒŒì‹±ë„ ì‹¤íŒ¨: {llm_message}")
        
        if not parsed:
            msg = "ê·œì¹™ì„ í•´ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”."
            if llm_message:
                msg += f" (ìƒì„¸: {llm_message})"
            logger.warning(f"[Top3Service] ê·œì¹™ íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {msg}")
            return msg, self.describe_rules()
        
        # ê·œì¹™ ì ìš©
        if parsed.get("reset"):
            self._last_instruction = ""
            self.set_rules(TOP3_RULE_DEFAULT)
            self.update_entity_rules({}, reset=True)
            self._save_rules()
            return "ê·œì¹™ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.", self.describe_rules()
        
        # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        weights = parsed.get("weights")
        if weights:
            self.set_rules(weights)
        
        # ì—”í‹°í‹° ê·œì¹™ ì—…ë°ì´íŠ¸
        entities = parsed.get("entities")
        if entities:
            self.update_entity_rules(entities, reset=False)
        
        self._last_instruction = cleaned_text
        self._save_rules()
        
        result_msg = "ê·œì¹™ì„ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤."
        if llm_message:
            result_msg += f" ({llm_message})"
        
        return result_msg, self.describe_rules()
    
    def _try_llm_parse_rules(self, text: str) -> Tuple[Optional[Dict], str]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ìì—°ì–´ ê·œì¹™ íŒŒì‹±"""
        # LLM ì„¤ì • í™•ì¸
        provider = os.environ.get("LLM_PROVIDER", "openai").lower()
        
        if provider == "openai":
            api_key = os.environ.get("OPENAI_API_KEY")
            url = "https://api.openai.com/v1/chat/completions"
            model = "gpt-4o-mini"
        elif provider == "azure":
            api_key = os.environ.get("AZURE_OPENAI_KEY")
            endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT", "").rstrip("/")
            deployment = os.environ.get("AZURE_OPENAI_DEPLOYMENT", "gpt-4o-mini")
            api_version = os.environ.get("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
            url = f"{endpoint}/openai/deployments/{deployment}/chat/completions?api-version={api_version}"
            model = deployment
        elif provider == "openrouter":
            api_key = os.environ.get("OPENROUTER_API_KEY")
            url = "https://openrouter.ai/api/v1/chat/completions"
            model = "openai/gpt-4o-mini"
        else:
            return None, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM ì œê³µì: {provider}"
        
        if not api_key:
            return None, "LLM API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = """ë‹¹ì‹ ì€ TODO ìš°ì„ ìˆœìœ„ ê·œì¹™ì„ í•´ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ì§€ì‹œì‚¬í•­ì„ JSON í˜•ì‹ì˜ ê·œì¹™ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

**ì¤‘ìš”: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.**

**ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œì— ë”°ë¥¸ ë³´ë„ˆìŠ¤ ì ìˆ˜ ê°€ì´ë“œ**
- "ìµœìš°ì„ ", "ë¬´ì¡°ê±´", "í•­ìƒ", "ë°˜ë“œì‹œ", "ê°€ì¥ ë¨¼ì €", "ì œì¼": requester ë³´ë„ˆìŠ¤ 8.0~10.0 (ë§¤ìš° ë†’ê²Œ!)
- "ìš°ì„ ", "ì¤‘ìš”", "ë¨¼ì €": requester ë³´ë„ˆìŠ¤ 4.0~6.0
- "ë³´í†µ", "ì¼ë°˜": requester ë³´ë„ˆìŠ¤ 2.0~3.0
- "ë‚®ìŒ", "ë‚˜ì¤‘ì—": requester ë³´ë„ˆìŠ¤ 0.5~1.5

**ì‘ë‹µ í˜•ì‹:**
{
  "reset": false,
  "weights": {
    "priority_high": 3.0,
    "priority_medium": 2.0,
    "priority_low": 1.0,
    "deadline_emphasis": 24.0
  },
  "entities": {
    "requester": {"ê¹€ì² ìˆ˜": 8.0, "ì´ì˜í¬": 4.0},
    "keyword": {"ê¸´ê¸‰": 3.0, "ë²„ê·¸": 2.5},
    "type": {"ë²„ê·¸ìˆ˜ì •": 3.0, "ê¸°ëŠ¥ê°œë°œ": 2.0},
    "time_range": {"ì˜¤ëŠ˜": 5.0, "ì´ë²ˆì£¼": 3.0}
  },
  "filters": {
    "created_after": "2025-10-20",
    "created_before": "2025-10-28",
    "status": ["pending", "in_progress"]
  }
}

**ê·œì¹™:**
- reset: trueë©´ ëª¨ë“  ê·œì¹™ ì´ˆê¸°í™” (ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ "ì´ˆê¸°í™”", "ë¦¬ì…‹", "reset" ë“±ì„ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ!)
- weights: ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ (0~10)
  - priority_high/medium/low: ìš°ì„ ìˆœìœ„ë³„ ê¸°ë³¸ ê°€ì¤‘ì¹˜
  - deadline_emphasis: ë°ë“œë¼ì¸ ê°•ì¡° (ì‹œê°„ ë‹¨ìœ„)
- entities: ì—”í‹°í‹°ë³„ ë³´ë„ˆìŠ¤ ì ìˆ˜ (0~10)
  - requester: ìš”ì²­ì ì´ë¦„ (ìµœìš°ì„ ì€ 8.0 ì´ìƒ!)
  - keyword: ì œëª©/ë‚´ìš©ì˜ í‚¤ì›Œë“œ
  - type: TODO ìœ í˜•
  - time_range: ì‹œê°„ ë²”ìœ„ ("ì˜¤ëŠ˜", "ì´ë²ˆì£¼", "ì´ë²ˆë‹¬" ë“±)
- filters: í•„í„° ì¡°ê±´ (ì„ íƒì‚¬í•­)
  - created_after/before: ìƒì„± ë‚ ì§œ ë²”ìœ„
  - status: ìƒíƒœ í•„í„°

**ì¤‘ìš”: resetì€ ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì´ˆê¸°í™”ë¥¼ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ trueë¡œ ì„¤ì •í•˜ì„¸ìš”!**
**ì¼ë°˜ì ì¸ ê·œì¹™ ì¶”ê°€ ìš”ì²­ì—ëŠ” resetì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”!**

**ì˜ˆì‹œ:**
ì…ë ¥: "ìœ ì¤€ì˜ ìµœìš°ì„ "
ì¶œë ¥: {"entities": {"requester": {"ìœ ì¤€ì˜": 9.0}}}

ì…ë ¥: "ìš”ì²­ìê°€ ì „í˜•ìš°ì¼ ê²½ìš° ìš°ì„ ìˆœìœ„ ë†’ê²Œ"
ì¶œë ¥: {"entities": {"requester": {"ì „í˜•ìš°": 5.0}}}

ì…ë ¥: "ë²„ê·¸ ë³´ê³ ì„œëŠ” ê¸´ê¸‰í•˜ê²Œ"
ì¶œë ¥: {"entities": {"keyword": {"ë²„ê·¸": 4.0, "ë³´ê³ ì„œ": 3.0}, "type": {"ë²„ê·¸": 4.0}}}

ì…ë ¥: "ì˜¤ëŠ˜ ìƒì„±ëœ TODO ìš°ì„ "
ì¶œë ¥: {"entities": {"time_range": {"ì˜¤ëŠ˜": 5.0}}, "filters": {"created_after": "2025-10-28"}}

ì…ë ¥: "ì´ë²ˆì£¼ ë°ë“œë¼ì¸ ê°•ì¡°"
ì¶œë ¥: {"weights": {"deadline_emphasis": 48.0}, "entities": {"time_range": {"ì´ë²ˆì£¼": 4.0}}}

ì…ë ¥: "ê¹€ì² ìˆ˜ ìš°ì„ , ë²„ê·¸ ê´€ë ¨ ì¤‘ìš”"
ì¶œë ¥: {"entities": {"requester": {"ê¹€ì² ìˆ˜": 5.0}, "keyword": {"ë²„ê·¸": 3.5}}}

ì…ë ¥: "ì´ˆê¸°í™”"
ì¶œë ¥: {"reset": true}
"""
        
        try:
            import requests
            
            headers = {"Authorization": f"Bearer {api_key}"}
            if provider == "openrouter":
                headers["HTTP-Referer"] = "https://github.com/your-repo"
            
            # AzureëŠ” JSON í˜•ì‹ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•´ì•¼ í•¨
            user_message = text
            if provider == "azure":
                user_message = f"{text}\n\në°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
            
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                "temperature": 0.3,
            }
            
            if provider in ("openai", "openrouter"):
                payload["response_format"] = {"type": "json_object"}
            
            logger.info("[Top3Service][LLM] provider=%s URL=%s text=%s", provider, url[:100], text[:200])
            logger.debug("[Top3Service][LLM] payload=%s", json.dumps(payload, ensure_ascii=False)[:500])
            
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            
            if response.status_code != 200:
                error_detail = response.text[:500]
                logger.error("[Top3Service][LLM] HTTP %d: %s", response.status_code, error_detail)
            
            response.raise_for_status()
            resp_json = response.json()
            
            logger.debug("[Top3Service][LLM] response=%s", json.dumps(resp_json, ensure_ascii=False)[:500])
            
            choices = resp_json.get("choices") or []
            if not choices:
                logger.error("[Top3Service][LLM] ì‘ë‹µì— choicesê°€ ì—†ìŒ: %s", json.dumps(resp_json, ensure_ascii=False)[:500])
                return None, "LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            
            content = choices[0].get("message", {}).get("content", "")
            logger.debug("[Top3Service][LLM] content=%s", content[:500])
            
            if not content or not content.strip():
                logger.error("[Top3Service][LLM] ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                return None, "LLM ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed = json.loads(content)
                logger.info("[Top3Service] LLM íŒŒì‹± ì„±ê³µ: %s", json.dumps(parsed, ensure_ascii=False)[:200])
                return parsed, "LLM íŒŒì‹± ì„±ê³µ"
            except json.JSONDecodeError as json_err:
                logger.error("[Top3Service][LLM] JSON íŒŒì‹± ì‹¤íŒ¨: %s, content=%s", json_err, content[:200])
                # JSONì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
                return None, f"JSON íŒŒì‹± ì‹¤íŒ¨: {json_err}"
            
        except requests.RequestException as exc:
            logger.warning("[Top3Service][LLM] request error: %s", exc)
            return None, f"LLM ìš”ì²­ ì‹¤íŒ¨: {exc}"
        except Exception as exc:
            logger.warning("[Top3Service][LLM] processing error: %s", exc)
            import traceback
            logger.debug(traceback.format_exc())
            return None, f"LLM ì²˜ë¦¬ ì˜¤ë¥˜: {exc}"
    
    def _heuristic_parse_rules(self, text: str) -> Tuple[Optional[Dict], str]:
        """íœ´ë¦¬ìŠ¤í‹± ë°©ì‹ìœ¼ë¡œ ìì—°ì–´ ê·œì¹™ íŒŒì‹±"""
        lower = text.lower()
        
        logger.debug(f"[Top3Service] íœ´ë¦¬ìŠ¤í‹± íŒŒì‹± ì‹œì‘: '{text}'")
        
        # ì´ˆê¸°í™” í‚¤ì›Œë“œ
        if any(word in lower for word in ["ì´ˆê¸°í™”", "ë¦¬ì…‹", "reset", "ê¸°ë³¸ê°’"]):
            logger.debug("[Top3Service] ì´ˆê¸°í™” í‚¤ì›Œë“œ ê°ì§€")
            return {"reset": True}, "íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì´ˆê¸°í™” ëª…ë ¹ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤."
        
        # ë³µí•© ì¡°ê±´ ê°ì§€ (LLMìœ¼ë¡œ ë„˜ê¹€)
        complex_keywords = ["ì´ê³ ", "ì´ë©°", "ê·¸ë¦¬ê³ ", "and", "ì°¸ì¡°", "cc", "bcc", "ì§ì ‘", "to"]
        if any(keyword in lower for keyword in complex_keywords):
            logger.debug(f"[Top3Service] ë³µí•© ì¡°ê±´ ê°ì§€ - LLM íŒŒì‹±ìœ¼ë¡œ ì „í™˜")
            return None, "ë³µí•© ì¡°ê±´ì´ ê°ì§€ë˜ì–´ LLM íŒŒì‹±ì´ í•„ìš”í•©ë‹ˆë‹¤"
        
        result = {"weights": {}, "entities": {"requester": {}, "type": {}}}
        
        # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ (í™•ì¥)
        priority_weights = {}
        high_priority_words = ["high", "ë†’", "ê¸´ê¸‰", "ì¤‘ìš”", "ìµœìš°ì„ ", "ê¸‰í•¨", "ì‹œê¸‰", "ì œì¼", "ë†’ê²Œ", "ë†’ì€"]
        
        if any(word in lower for word in high_priority_words):
            current_high = priority_weights.get("priority_high", TOP3_RULE_DEFAULT["priority_high"])
            priority_weights["priority_high"] = max(current_high, TOP3_RULE_DEFAULT["priority_high"] + 2.0)
            logger.debug(f"[Top3Service] ë†’ì€ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ê°ì§€: priority_high={priority_weights['priority_high']:.2f}")
        
        if any(word in lower for word in ["medium", "ì¤‘ê°„", "ë³´í†µ"]):
            priority_weights["priority_medium"] = max(
                priority_weights.get("priority_medium", TOP3_RULE_DEFAULT["priority_medium"]),
                TOP3_RULE_DEFAULT["priority_medium"] + 0.5
            )
            logger.debug(f"[Top3Service] ì¤‘ê°„ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ê°ì§€: priority_medium={priority_weights['priority_medium']:.2f}")
        
        if any(word in lower for word in ["low", "ë‚®", "ëœ ì¤‘ìš”", "ë‚®ê²Œ", "ìµœí•˜ìœ„"]):
            priority_weights["priority_low"] = max(0.2, TOP3_RULE_DEFAULT["priority_low"] - 2.0)
            logger.debug(f"[Top3Service] ë‚®ì€ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ê°ì§€: priority_low={priority_weights['priority_low']:.2f}")
        
        if priority_weights:
            result["weights"].update(priority_weights)
        
        # ìš”ì²­ì í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë‹¤ë¥¸ ë³´ë„ˆìŠ¤)
        # ìµœìš°ì„  í‚¤ì›Œë“œ ì²´í¬
        is_top_priority = any(word in lower for word in ["ìµœìš°ì„ ", "ë¬´ì¡°ê±´", "í•­ìƒ", "ë°˜ë“œì‹œ", "ê°€ì¥ ë¨¼ì €", "ìµœê³ ", "ì œì¼"])
        is_high_priority = any(word in lower for word in ["ìš°ì„ ", "ì¤‘ìš”", "ë¨¼ì €", "ë†’ê²Œ", "ë†’ì€"])
        
        # ë³´ë„ˆìŠ¤ ì ìˆ˜ ê²°ì • (ì¡°ì •)
        if is_top_priority:
            name_bonus = 8.0  # ìµœìš°ì„ : ë§¤ìš° ë†’ì€ ë³´ë„ˆìŠ¤ (7.0 â†’ 8.0)
        elif is_high_priority:
            name_bonus = 4.0  # ìš°ì„ : ë†’ì€ ë³´ë„ˆìŠ¤ (3.5 â†’ 4.0)
        else:
            name_bonus = 2.0  # ê¸°ë³¸ ë³´ë„ˆìŠ¤
        
        logger.debug(f"[Top3Service] ìš”ì²­ì ë³´ë„ˆìŠ¤ ì ìˆ˜: {name_bonus:.1f} (ìµœìš°ì„ ={is_top_priority}, ìš°ì„ ={is_high_priority})")
        
        # ìš”ì²­ì ì´ë¦„ ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)
        # íŒ¨í„´ 1: "XXXì´/ê°€ ìš”ì²­ì" í˜•íƒœ
        requester_pattern1 = r"([ê°€-í£]{2,6})(?:ì´|ê°€)\s*ìš”ì²­ì"
        # íŒ¨í„´ 2: "ìš”ì²­ìê°€ XXXì¼ ê²½ìš°" í˜•íƒœ (ê°€ì¥ ì¼ë°˜ì )
        requester_pattern2 = r"ìš”ì²­ì(?:ê°€|ëŠ”|ì´)?\s*([ê°€-í£]{2,6})(?:ì¼|ì´)?\s*(?:ê²½ìš°|ë•Œ|ë©´)"
        # íŒ¨í„´ 3: ì¼ë°˜ í•œê¸€ ì´ë¦„ + í˜¸ì¹­
        requester_pattern3 = r"([ê°€-í£]{2,6})\s*(?:ë‹˜|ì”¨|ì„ ìƒë‹˜|íŒ€ì¥|ë¶€ì¥)"
        # íŒ¨í„´ 4: "XXX ìš”ì²­" í˜•íƒœ
        requester_pattern4 = r"([ê°€-í£]{2,6})\s*ìš”ì²­"
        
        matches = set()
        matches.update(re.findall(requester_pattern1, text))
        matches.update(re.findall(requester_pattern2, text))
        matches.update(re.findall(requester_pattern3, text))
        matches.update(re.findall(requester_pattern4, text))
        
        logger.debug(f"[Top3Service] íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼: {matches}")
        
        # ë¶ˆìš©ì–´ ì œê±° (ì¼ë°˜ì ì¸ ë‹¨ì–´ ì œì™¸) - í™•ì¥
        stopwords = {
            "ìš”ì²­ì", "ìš°ì„ ìˆœìœ„", "ìµœìš°ì„ ", "ê²½ìš°", "ìš°ì„ ", "ì¤‘ìš”", "ë¨¼ì €", "ë†’ê²Œ", "ë†’ì€", "ì œì¼",
            "ìš”ì²­", "ìˆœìœ„", "ê·œì¹™", "ì„¤ì •", "ë³€ê²½", "ìˆ˜ì •", "ì¶”ê°€", "ì‚­ì œ", "ì´ˆê¸°í™”", "ë¦¬ì…‹"
        }
        matches = {name for name in matches if name not in stopwords and len(name) >= 2}
        
        # "XXXì¼", "XXXì´" í˜•íƒœ ì œê±° (ì˜ˆ: "ì •ì§€ì›ì¼" â†’ "ì •ì§€ì›", "ê¹€ì„¸ë¦°ì´" â†’ "ê¹€ì„¸ë¦°")
        cleaned_matches = set()
        for name in matches:
            cleaned_name = name
            # "ì¼" ì œê±°
            if name.endswith("ì¼") and len(name) > 2:
                cleaned_name = name[:-1]
                logger.debug(f"[Top3Service] ì´ë¦„ ì •ë¦¬ (ì¼): {name} â†’ {cleaned_name}")
            # "ì´" ì œê±° (ì¡°ì‚¬)
            elif name.endswith("ì´") and len(name) > 2:
                cleaned_name = name[:-1]
                logger.debug(f"[Top3Service] ì´ë¦„ ì •ë¦¬ (ì´): {name} â†’ {cleaned_name}")
            
            if len(cleaned_name) >= 2:
                cleaned_matches.add(cleaned_name)
        
        matches = cleaned_matches
        
        logger.debug(f"[Top3Service] ì¶”ì¶œëœ ì´ë¦„ í›„ë³´: {matches}")
        
        for name in matches:
            result["entities"]["requester"][name] = name_bonus
            logger.debug(f"[Top3Service] ìš”ì²­ì ê·œì¹™ ì¶”ê°€: {name} â†’ ë³´ë„ˆìŠ¤ {name_bonus:.1f}")
            
            # í•œêµ­ì–´ ì´ë¦„ ì •ê·œí™”
            from .top3_korean_utils import normalize_korean_name
            normalized = normalize_korean_name(name)
            if normalized != name:
                result["entities"]["requester"][normalized] = name_bonus
                logger.debug(f"[Top3Service] ì •ê·œí™”ëœ ì´ë¦„ ì¶”ê°€: {normalized} â†’ ë³´ë„ˆìŠ¤ {name_bonus:.1f}")
        
        # ìœ í˜•(type) í‚¤ì›Œë“œ ì¶”ì¶œ
        # íŒ¨í„´: "XXX ìœ í˜•", "XXX íƒ€ì…", "XXX ê´€ë ¨", "XXX TODO"
        type_pattern1 = r"([ê°€-í£a-zA-Z]{2,10})\s*(?:ìœ í˜•|íƒ€ì…|ê´€ë ¨|TODO)"
        # íŒ¨í„´: "ìœ í˜•ì´ XXX", "íƒ€ì…ì´ XXX"
        type_pattern2 = r"(?:ìœ í˜•|íƒ€ì…)(?:ì´|ê°€)?\s*([ê°€-í£a-zA-Z]{2,10})"
        
        type_matches = set()
        type_matches.update(re.findall(type_pattern1, text))
        type_matches.update(re.findall(type_pattern2, text))
        
        # ë¶ˆìš©ì–´ ì œê±°
        type_stopwords = {"ìœ í˜•", "íƒ€ì…", "ê´€ë ¨", "TODO", "ê²½ìš°", "ìš°ì„ ", "ì¤‘ìš”", "ë¨¼ì €", "ë†’ê²Œ"}
        type_matches = {t for t in type_matches if t not in type_stopwords and len(t) >= 2}
        
        logger.debug(f"[Top3Service] ì¶”ì¶œëœ ìœ í˜• í›„ë³´: {type_matches}")
        
        for type_name in type_matches:
            result["entities"]["type"][type_name] = name_bonus
            logger.debug(f"[Top3Service] ìœ í˜• ê·œì¹™ ì¶”ê°€: {type_name} â†’ ë³´ë„ˆìŠ¤ {name_bonus:.1f}")
        
        # ê²°ê³¼ í™•ì¸
        if not result["weights"] and not result["entities"]["requester"] and not result["entities"]["type"]:
            return None, "ê·œì¹™ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        
        note = "íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ê·œì¹™ì„ í•´ì„í–ˆìŠµë‹ˆë‹¤."
        if result["entities"]["requester"]:
            note += f" (ìš”ì²­ì: {', '.join(result['entities']['requester'].keys())})"
        if result["entities"]["type"]:
            note += f" (ìœ í˜•: {', '.join(result['entities']['type'].keys())})"
        
        return result, note
    
    def _save_rules(self) -> None:
        """ê·œì¹™ì„ íŒŒì¼ì— ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            
            data = {
                "weights": self.get_rules(),
                "entities": self.get_entity_rules(),
                "instruction": self._last_instruction
            }
            
            with open(self.config_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info("[Top3Service] rules saved to %s", self.config_path)
        except Exception as exc:
            logger.error("[Top3Service] failed to save rules: %s", exc)
    
    def _load_rules(self) -> None:
        """íŒŒì¼ì—ì„œ ê·œì¹™ ë¡œë“œ"""
        try:
            if not os.path.exists(self.config_path):
                return
            
            with open(self.config_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            weights = data.get("weights")
            entities = data.get("entities")
            instruction = data.get("instruction")
            
            if isinstance(weights, dict) and weights:
                self.set_rules(weights)
            
            if isinstance(entities, dict):
                self.update_entity_rules(entities, reset=True)
            
            if isinstance(instruction, str):
                self._last_instruction = instruction
            
            logger.info("[Top3Service] rules loaded from %s", self.config_path)
        except Exception as exc:
            logger.warning("[Top3Service] failed to load rules: %s", exc)
