# Top3 RAG 선정 시스템 가이드

## 개요

Smart Assistant v1.4.0에서 도입된 LLM 기반 Top3 RAG(Retrieval-Augmented Generation) 선정 시스템은 자연어로 입력한 규칙을 바탕으로 지능적으로 TODO 우선순위를 결정합니다.

## 주요 특징

### 🤖 LLM 기반 지능형 선정
- **자연어 규칙**: 복잡한 조건을 자연어로 간단히 표현
- **문맥 이해**: 프로젝트 태그, 요청자, 키워드 등을 종합적으로 분석
- **유연한 해석**: 동일한 의미의 다양한 표현 방식 지원

### 🔄 스마트 폴백 시스템
- **자동 전환**: LLM 실패 시 점수 기반 시스템으로 즉시 전환
- **연속 실패 보호**: 3회 연속 실패 시 자동으로 LLM 비활성화
- **수동 재활성화**: 문제 해결 후 수동으로 LLM 모드 재활성화 가능

### ⚡ 성능 최적화
- **캐시 시스템**: 동일한 규칙 재사용 시 즉시 응답 (TTL 5분)
- **사전 필터링**: 50개 이상 TODO 시 규칙 매칭 항목만 LLM 처리
- **배치 처리**: 여러 TODO를 효율적으로 일괄 처리

## 사용 방법

### 1. 기본 설정

**환경 변수 설정** (`.env` 파일):
```bash
# LLM 제공자 선택 (택일)
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here

# 또는
LLM_PROVIDER=azure
AZURE_OPENAI_KEY=your-key
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-4o

# 또는
LLM_PROVIDER=openrouter
OPENROUTER_API_KEY=sk-or-your-key-here
```

**고급 설정** (선택사항):
```bash
TOP3_LLM_TIMEOUT=30        # LLM 호출 타임아웃 (초)
TOP3_CACHE_TTL=300         # 캐시 유효 시간 (초)
TOP3_MAX_CANDIDATES=50     # 사전 필터링 임계값
```

### 2. 자연어 규칙 입력

GUI의 좌측 패널에서 "Top3 규칙" 섹션을 찾아 자연어로 규칙을 입력합니다.

## 자연어 규칙 예시

### 요청자 기반 규칙

**기본 형태:**
```
유준영이 요청자일 경우 우선순위 높게
김세린 최우선
전형우님 요청 먼저 처리
```

**우선순위 키워드:**
- **최우선**: "최우선", "무조건", "항상", "반드시", "가장 먼저", "제일"
- **높은 우선순위**: "우선", "중요", "먼저", "높게", "높은"
- **일반**: 키워드 없음 또는 "보통", "일반"

### 프로젝트 태그 기반 규칙

```
CARE 프로젝트 관련 TODO 우선 처리
HealthApp 프로젝트 최우선
WC 프로젝트는 낮은 우선순위
HEAL 프로젝트이면서 버그 관련이면 긴급
```

### 키워드 기반 규칙

```
버그 관련 TODO 긴급 처리
미팅 관련 항목 우선
긴급 키워드 포함 시 최우선
검토 요청은 높은 우선순위
```

### 시간 범위 규칙

```
오늘 생성된 TODO 우선
이번주 마감 항목 먼저
최근 3일 내 TODO 높은 우선순위
내일까지 마감인 항목 최우선
```

### 복합 조건 규칙

```
유준영이 요청하고 버그 관련이면 최우선
CARE 프로젝트이면서 오늘 생성된 TODO 우선
김세린 요청이고 미팅 관련이면 높은 우선순위
긴급하고 이번주 마감이면 무조건 처리
```

## 작동 방식

### 1. 규칙 파싱
1. **LLM 파싱**: Azure OpenAI/OpenAI/OpenRouter를 사용하여 자연어 규칙을 구조화된 데이터로 변환
2. **휴리스틱 파싱**: LLM 실패 시 정규표현식 기반으로 기본적인 규칙 추출
3. **규칙 저장**: 파싱된 규칙을 `top3_config.json`에 저장

### 2. Top3 선정 과정
1. **후보 필터링**: status가 "done"이 아닌 TODO만 선정 대상
2. **규칙 매칭**: 자연어 규칙에 해당하는 TODO 필터링
3. **LLM 선정**: 매칭된 TODO를 LLM에 전달하여 Top3 선정
4. **폴백 처리**: LLM 실패 시 점수 기반 선정으로 전환

### 3. 캐시 시스템
- **캐시 키**: 규칙 텍스트 + TODO 목록 해시값
- **TTL**: 5분 (300초)
- **자동 무효화**: 새로운 TODO 추가 시 캐시 자동 갱신

## 모드별 동작

### LLM 모드 (자연어 규칙 있음)
```
📊 현재 모드: 🤖 LLM 모드
규칙: "유준영이 요청자일 경우 우선순위 높게"
선정 방식: 자연어 규칙 기반 지능형 선정
```

**특징:**
- 복잡한 조건과 문맥을 이해
- 동일한 의미의 다양한 표현 지원
- 프로젝트 태그와 요청자 정보 종합 분석

### 강제 모드 (자연어 규칙 있음 + LLM 비활성화)
```
📊 현재 모드: 🔒 강제 모드
규칙: "유준영이 요청자일 경우 우선순위 높게"
선정 방식: 자연어 규칙에 맞는 TODO만 Top3 표시 (LLM 비활성화)
```

**특징:**
- 규칙에 정확히 매칭되는 TODO만 선정
- LLM 없이 점수 기반으로 우선순위 계산
- 안정적이지만 유연성 제한

### 일반 모드 (자연어 규칙 없음)
```
📊 현재 모드: 📊 일반 모드
선정 방식: 점수 기반 Top3 선정
```

**특징:**
- 우선순위, 마감일, 근거 수 등을 수치로 계산
- 예측 가능하고 일관된 결과
- 규칙 없이도 안정적으로 동작

## 성능 최적화

### 사전 필터링
TODO가 50개 이상인 경우:
1. 규칙에 매칭되는 TODO만 먼저 필터링
2. 필터링된 TODO만 LLM에 전달
3. 토큰 사용량 및 응답 시간 대폭 단축

### 캐시 활용
```
[Top3Service] 캐시 히트: 즉시 응답 (0.1초)
[Top3Service] 캐시 미스: LLM 호출 (3.2초)
```

### 배치 처리
- 여러 TODO를 한 번의 LLM 호출로 처리
- API 호출 횟수 최소화
- 비용 효율성 향상

## 문제 해결

### LLM 선정이 작동하지 않음

**확인 사항:**
1. **API 키 설정**: `.env` 파일에 올바른 API 키 설정
2. **제공자 설정**: `LLM_PROVIDER` 환경 변수 확인
3. **네트워크 연결**: 인터넷 연결 및 방화벽 설정
4. **로그 확인**: DEBUG 레벨로 상세 로그 확인

**로그 예시:**
```bash
# 정상 동작
[Top3Service] 🤖 LLM 모드: 자연어 규칙 기반 Top3 선정 시도
[Top3Service] ✅ LLM 선정 성공: 3개 선정

# API 키 오류
[Top3Service] ❌ LLM 선정 실패 (1/3): Invalid API key
[Top3Service] 📊 폴백: 점수 기반 선정으로 전환

# 연속 실패
[Top3Service] 🚫 LLM 연속 3회 실패 - 점수 기반 선정으로 자동 전환됩니다
```

### 규칙에 맞는 TODO가 없음

**원인:**
- 요청자 이름 불일치
- 프로젝트 태그 없음
- 키워드 매칭 실패

**해결 방법:**
1. **실제 데이터 확인**: TODO 목록에서 요청자 이름과 프로젝트 태그 확인
2. **규칙 수정**: 더 넓은 범위의 규칙 사용
3. **부분 매칭**: 정확한 이름 대신 부분 이름 사용

### 성능이 느림

**최적화 방법:**
1. **타임아웃 단축**: `TOP3_LLM_TIMEOUT=15`로 설정
2. **캐시 TTL 연장**: `TOP3_CACHE_TTL=600` (10분)
3. **사전 필터링 임계값 조정**: `TOP3_MAX_CANDIDATES=30`

## 모니터링

### 로그 레벨 설정
```bash
set LOG_LEVEL=DEBUG
python run_gui.py
```

### 주요 로그 메시지
- `[Top3Service]`: Top3 선정 관련 로그
- `[LLMClient]`: LLM API 호출 로그
- `[Top3CacheManager]`: 캐시 관련 로그

### 성능 메트릭
- **LLM 응답 시간**: 평균 3-5초
- **캐시 히트율**: 80% 이상 권장
- **토큰 사용량**: 규칙당 평균 500-1000 토큰

## 비용 관리

### 토큰 사용량 추정
- **기본 프롬프트**: ~300 토큰
- **TODO 1개당**: ~50 토큰
- **응답**: ~100 토큰
- **총 예상**: 규칙당 500-1000 토큰

### 비용 절약 팁
1. **캐시 활용**: 동일한 규칙 재사용
2. **사전 필터링**: 대량 TODO 시 필터링 활용
3. **적절한 TTL**: 너무 짧지 않게 설정
4. **OpenRouter 사용**: 더 저렴한 모델 선택 가능

## 향후 개선 계획

### v1.4.1 (예정)
- [ ] 규칙 템플릿 제공
- [ ] 시각적 규칙 빌더
- [ ] 성능 대시보드

### v1.5.0 (예정)
- [ ] 다국어 규칙 지원
- [ ] 학습 기반 규칙 추천
- [ ] 고급 필터링 옵션

## 참고 자료

- [Smart Assistant README](../README.md)
- [문제 해결 가이드](../TROUBLESHOOTING.md)
- [개발 가이드](DEVELOPMENT.md)
- [API 문서](API.md)